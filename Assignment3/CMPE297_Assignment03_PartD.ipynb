{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNQl9APEDKdLT+qzHgQptpG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ukVVAgV7dAsg"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"pPSP7K6CLeNW"}},{"cell_type":"code","source":["%%capture\n","!pip install unsloth\n","# Also get the latest nightly Unsloth!\n","!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""],"metadata":{"id":"-PE64snMLecm","executionInfo":{"status":"ok","timestamp":1732926761069,"user_tz":480,"elapsed":43595,"user":{"displayName":"Dhruval Shah","userId":"16877617780739273734"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from google.colab import userdata\n","HF_TOKEN = userdata.get('HF_TOKEN')"],"metadata":{"id":"NGoI_ak-MRWB","executionInfo":{"status":"ok","timestamp":1732926765296,"user_tz":480,"elapsed":559,"user":{"displayName":"Dhruval Shah","userId":"16877617780739273734"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# One must patch the DPO Trainer first!\n","from unsloth import PatchDPOTrainer\n","PatchDPOTrainer()"],"metadata":{"id":"RxawNHQ8MRTx","colab":{"base_uri":"https://localhost:8080/","height":456},"outputId":"6f64eade-7aae-4a2d-d56a-b0abb040068d","executionInfo":{"status":"error","timestamp":1732926770286,"user_tz":480,"elapsed":251,"user":{"displayName":"Dhruval Shah","userId":"16877617780739273734"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/unsloth/__init__.py:44: UserWarning: Unsloth: 'CUDA_VISIBLE_DEVICES' is currently -1 \n","Unsloth currently does not support multi GPU setups - but we are working on it!\n","Multiple CUDA devices detected but we require a single device.\n","We will override CUDA_VISIBLE_DEVICES to first device: -1.\n","  warnings.warn(\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-3665ec77d20e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# One must patch the DPO Trainer first!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0munsloth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPatchDPOTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mPatchDPOTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m# Torch 2.4 has including_emulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mmajor_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_capability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0mSUPPORTS_BFLOAT16\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmajor_version\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmajor\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mminor\u001b[0m \u001b[0mcuda\u001b[0m \u001b[0mcapability\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \"\"\"\n\u001b[0;32m--> 509\u001b[0;31m     \u001b[0mprop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0m_CudaDeviceProperties\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mproperties\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \"\"\"\n\u001b[0;32m--> 523\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# will define _get_device_properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"]}]},{"cell_type":"markdown","source":["## DPO Zephyr Unsloth Example"],"metadata":{"id":"8g7tKNcyLjXf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QmUBVEnvCDJv","colab":{"base_uri":"https://localhost:8080/","height":313,"referenced_widgets":["11c6851617034530b30c0d8ededabce8","c3e909f3e207485e97214e6096fa1b8c","baefaa858a374b7ba888c9c79834b6d9","0a4f35747a0d4737b0efd51be37d5ebb","350b06137ee7488f8f19bc5fe1af6e5c","36dcad22825a45c99f26d75ded406199","47f9b4a2e3fe451f89fb111f9b83c978","2d5dd364491e4553b089437b48569e86","0c3054e5f2e14832b303ffc9df8ecb8a","28ab68e0e5914e318741182e4d1a7ebe","28a8781d95bc4b68a3c27492d8d5a79c","2d3b1f8845374ad5b17f257afa9b75fc","3eac0ef8e50a4ca7957d2f253ad75e68","d0804a5f1fd342359488c55b91a363ba","8a9a89c465ed4913bef31f612c10f7d7","b7733813fa414d1cb0f679f466b25b6e","3b6aaa16ff004301aa9c71532eeee670","56d0ca2fb9f04a0696258aa1a328f1db","ea48ea76500549988537502dd3830509","b1698a5f835d4ffbbd82162337b5b280","68074d0559f24b73a7f7b68c27cba803","f319c4919d6d4009ad33023a47130710","470b75621d7143a2b7c6031f43010c41","55eabc808d7e4483b25fc21bbc7d2662","b4d41ccdebf6443b8855b17ef1e0ccb0","10ab0ff0efe04130927e43a183260a24","59e460d5e0374f9cb6e2b37b314fdade","25f1ed192a0846c88f95e996d618a5ec","2d01ee8e7fdb4fecad6a02a0b9321410","8b0ac0ca5f4e42348ea2e292abd9f455","4612c25a65cd429bae1775ab76527221","3e88b4d8499d432e9e8d7675e14d0edf","4b389ab0296f455f8527f2287f2dd369","fea3b0c506864f75976f1fbb244f5be3","debbd364a1b645cba235937173967264","f2785fa869664a039eb0ae7f03a10124","8efe6e54ede24fcca8925d07a8e51958","610b1d2fd51e4537b4cfa2cb14b2ce23","67f1e5b9207d43cda783ce460fad8aa8","d7b2c969a01d4e528f10a697ef69e912","911291c2240c406eb3b3c33d4defce8a","17c2d35f8c924ad3b6870ac4e59ca86d","c037df27307e4951b40396e2523e989f","ea644037537c471ea549b0ed831c05b1","70b45881df6a4eba865b892ce81e11fe","9a77470eef4940038d9d928ed938e695","ab85fe8b0aa34b238eb9d89a5e36f3ca","9df72a072a8641898c5512c2d3927011","00b14e1034b24f77b55f0c343924c95f","69c0a94517c345b983bcc06ded014a59","1749f65e135c4b7b9347f1e7b29c96ff","3f6d17620cd540e68ffd3e39413b2502","698ff1da95364bfcb110de9d924622ad","214f94186d864b07a9904bb029315c0b","9683097dac0e4735a980d7e31d99656c","dca47290503f490eaf0a976de0a137fe","fd7919e8aa2545a7b80631661ae325ce","6b56c838e573456f99123d2b4a9feec0","de2d740dcdb241c0ae175bd46aec2979","550d389c196844ed9c3c7ebca68b6019","1c0862ef16cd4d95aee00c445f550e2d","5ca99fa4349e4968ad7d41763419e21d","8f5a7bc92bf840db9f76ee7d66f0ee3b","4014c0ef09034ed28c11ca098ad9e72a","c24c6e4effde4388b3a7f9692ad8837d","98288c6036da4cdd9e65e1623a3f6a38"]},"outputId":"e140a9de-b460-4cbf-d4fc-5c3b8e3d3b01"},"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2024.9.post4: Fast Mistral patching. Transformers = 4.44.2.\n","   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.4.1+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/4.13G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11c6851617034530b30c0d8ededabce8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/155 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d3b1f8845374ad5b17f257afa9b75fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.54k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"470b75621d7143a2b7c6031f43010c41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fea3b0c506864f75976f1fbb244f5be3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/511 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70b45881df6a4eba865b892ce81e11fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dca47290503f490eaf0a976de0a137fe"}},"metadata":{}}],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 4096 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/zephyr-sft-bnb-4bit\", # Choose ANY! eg mistralai/Mistral-7B-Instruct-v0.2\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AqkY_wHdKyOl"},"outputs":[],"source":["import os\n","import re\n","from typing import List, Literal, Optional\n","\n","from datasets import DatasetDict, concatenate_datasets, load_dataset, load_from_disk\n","from datasets.builder import DatasetGenerationError\n","\n","\n","DEFAULT_CHAT_TEMPLATE = \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\"\n","\n","\n","def apply_chat_template(\n","    example, tokenizer, task: Literal[\"sft\", \"generation\", \"rm\", \"dpo\"] = \"sft\", assistant_prefix=\"<|assistant|>\\n\"\n","):\n","    def _strip_prefix(s, pattern):\n","        # Use re.escape to escape any special characters in the pattern\n","        return re.sub(f\"^{re.escape(pattern)}\", \"\", s)\n","\n","    if task in [\"sft\", \"generation\"]:\n","        messages = example[\"messages\"]\n","        # We add an empty system message if there is none\n","        if messages[0][\"role\"] != \"system\":\n","            messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n","        example[\"text\"] = tokenizer.apply_chat_template(\n","            messages, tokenize=False, add_generation_prompt=True if task == \"generation\" else False\n","        )\n","    elif task == \"rm\":\n","        if all(k in example.keys() for k in (\"chosen\", \"rejected\")):\n","            chosen_messages = example[\"chosen\"]\n","            rejected_messages = example[\"rejected\"]\n","            # We add an empty system message if there is none\n","            if chosen_messages[0][\"role\"] != \"system\":\n","                chosen_messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n","            if rejected_messages[0][\"role\"] != \"system\":\n","                rejected_messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n","            example[\"text_chosen\"] = tokenizer.apply_chat_template(chosen_messages, tokenize=False)\n","            example[\"text_rejected\"] = tokenizer.apply_chat_template(rejected_messages, tokenize=False)\n","        else:\n","            raise ValueError(\n","                f\"Could not format example as dialogue for `rm` task! Require `[chosen, rejected]` keys but found {list(example.keys())}\"\n","            )\n","    elif task == \"dpo\":\n","        if all(k in example.keys() for k in (\"chosen\", \"rejected\")):\n","            # Compared to reward modeling, we filter out the prompt, so the text is everything after the last assistant token\n","            prompt_messages = [[msg for msg in example[\"chosen\"] if msg[\"role\"] == \"user\"][0]]\n","            # Insert system message\n","            if example[\"chosen\"][0][\"role\"] != \"system\":\n","                prompt_messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n","            else:\n","                prompt_messages.insert(0, example[\"chosen\"][0])\n","            # TODO: handle case where chosen/rejected also have system messages\n","            chosen_messages = example[\"chosen\"][1:]\n","            rejected_messages = example[\"rejected\"][1:]\n","            example[\"text_chosen\"] = tokenizer.apply_chat_template(chosen_messages, tokenize=False)\n","            example[\"text_rejected\"] = tokenizer.apply_chat_template(rejected_messages, tokenize=False)\n","            example[\"text_prompt\"] = tokenizer.apply_chat_template(\n","                prompt_messages, tokenize=False, add_generation_prompt=True\n","            )\n","            example[\"text_chosen\"] = _strip_prefix(example[\"text_chosen\"], assistant_prefix)\n","            example[\"text_rejected\"] = _strip_prefix(example[\"text_rejected\"], assistant_prefix)\n","        else:\n","            raise ValueError(\n","                f\"Could not format example as dialogue for `dpo` task! Require `[chosen, rejected]` keys but found {list(example.keys())}\"\n","            )\n","    else:\n","        raise ValueError(\n","            f\"Task {task} not supported, please ensure that the provided task is one of {['sft', 'generation', 'rm', 'dpo']}\"\n","        )\n","    return example\n","\n","\n","def get_datasets(\n","    data_config: dict,\n","    splits: List[str] = [\"train\", \"test\"],\n","    shuffle: bool = True,\n",") -> DatasetDict:\n","    \"\"\"\n","    Loads one or more datasets with varying training set proportions.\n","\n","    Args:\n","        data_config (`DataArguments` or `dict`):\n","            Dataset configuration and split proportions.\n","        splits (`List[str]`, *optional*, defaults to `['train', 'test']`):\n","            Dataset splits to load and mix. Assumes the splits exist in all datasets and have a `train_` or `test_` prefix.\n","        shuffle (`bool`, *optional*, defaults to `True`):\n","            Whether to shuffle the training and testing/validation data.\n","\n","    Returns\n","        [`DatasetDict`]: The dataset dictionary containing the loaded datasets.\n","    \"\"\"\n","\n","    if type(data_config) is dict:\n","        # Structure of the input is:\n","        #     dataset_mixer = {\n","        #             \"dataset1\": 0.5,\n","        #             \"dataset1\": 0.3,\n","        #             \"dataset1\": 0.2,\n","        #         }\n","        dataset_mixer = data_config\n","    else:\n","        raise ValueError(f\"Data config {data_config} not recognized.\")\n","\n","    raw_datasets = mix_datasets(dataset_mixer, splits=splits, shuffle=shuffle)\n","    return raw_datasets\n","\n","\n","def mix_datasets(dataset_mixer: dict, splits: Optional[List[str]] = None, shuffle=True) -> DatasetDict:\n","    \"\"\"\n","    Loads and mixes datasets according to proportions specified in `dataset_mixer`.\n","\n","    Args:\n","        dataset_mixer (`dict`):\n","            Dictionary containing the dataset names and their training proportions. By default, all test proportions are 1.\n","        splits (Optional[List[str]], *optional*, defaults to `None`):\n","            Dataset splits to load and mix. Assumes the splits exist in all datasets and have a `train_` or `test_` prefix.\n","        shuffle (`bool`, *optional*, defaults to `True`):\n","            Whether to shuffle the training and testing/validation data.\n","    \"\"\"\n","    raw_datasets = DatasetDict()\n","    raw_train_datasets = []\n","    raw_val_datasets = []\n","    fracs = []\n","    for ds, frac in dataset_mixer.items():\n","        fracs.append(frac)\n","        for split in splits:\n","            try:\n","                # Try first if dataset on a Hub repo\n","                dataset = load_dataset(ds, split=split)\n","            except DatasetGenerationError:\n","                # If not, check local dataset\n","                dataset = load_from_disk(os.path.join(ds, split))\n","\n","            if \"train\" in split:\n","                raw_train_datasets.append(dataset)\n","            elif \"test\" in split:\n","                raw_val_datasets.append(dataset)\n","            else:\n","                raise ValueError(f\"Split type {split} not recognized as one of test or train.\")\n","\n","    if any(frac < 0 for frac in fracs):\n","        raise ValueError(\"Dataset fractions cannot be negative.\")\n","\n","    if len(raw_train_datasets) > 0:\n","        train_subsets = []\n","        for dataset, frac in zip(raw_train_datasets, fracs):\n","            train_subset = dataset.select(range(int(frac * len(dataset))))\n","            train_subsets.append(train_subset)\n","        if shuffle:\n","            raw_datasets[\"train\"] = concatenate_datasets(train_subsets).shuffle(seed=42)\n","        else:\n","            raw_datasets[\"train\"] = concatenate_datasets(train_subsets)\n","    # No subsampling for test datasets to enable fair comparison across models\n","    if len(raw_val_datasets) > 0:\n","        if shuffle:\n","            raw_datasets[\"test\"] = concatenate_datasets(raw_val_datasets).shuffle(seed=42)\n","        else:\n","            raw_datasets[\"test\"] = concatenate_datasets(raw_val_datasets)\n","\n","    if len(raw_datasets) == 0:\n","        raise ValueError(\n","            f\"Dataset {dataset_mixer} not recognized with split {split}. Check the dataset has been correctly formatted.\"\n","        )\n","\n","    return raw_datasets"]},{"cell_type":"markdown","metadata":{"id":"EQ-Cp2V6kDcr"},"source":["### Data Prep"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":465,"referenced_widgets":["b80d2893ca824cbeb394bade07ba379a","85f0d0b75fc148cc8ec6dc62849659bd","fdc34e548f234df0a25117280faba71b","294c56bceb25488fb32187e11f497c41","518e5362c41c4718b5d147f48878aa35","e9b12cb928dc4a0b9530a8e28cd82dc3","0856e8e8533348e695de33f3ccb30cad","076eb5a91f5c455f927620b3878faab0","520878a4bde240cba6180f971464103b","3346d4685a824cc6a3fac938066c65cf","13952f4c182a4de889f717e8e303f034","171a028b33554c65a9106cabd65f3e1f","155e6bef22d2480292d73eb367128040","82017e441b99404e93d698c5afc0d949","097f84d3f2b742a5b16eb630de672821","b62384152b33438a8035d886cd96d11c","3996cda3852a46d88ed83ca2dbe50aad","c486d3027814401b987a16f24b29ba6d","1ed742d0611e48beb4f1e1bef6cf3b6b","f203e788224248a6be8811dde42d9fdf","bd5d6102eac94fd09f1e97d8a97174a2","0775e7720ed2460b9d555007399e54a9","14d6bbd363574039a16976d872b928dc","4d975648dc314926876536beebbf88fb","d652d4b388984b35ac60a9978d363f9e","e13061167ec74681b6db62a55cb97180","ec213c614c054385aa27e87941797195","8957b094aaae436097a43be0fc3348cc","63aa95c8ef824ad5ab66a49c93934df7","df306a0fff0544a49d378c467a172906","febcc05f70a94f1ea7bc90792e25657a","4c98ac97e27445d1af350a9a598f1e68","d554a85326c54bae8db2cc86036da502","1c234edacd9e4c24aa5f84c675ece817","4e2f5ea7f3164855a81f86f8ad0b8d72","6a863303b83249549da6230af0e7e87b","883bcbeb88f4474b86d5707cc5e1a2a0","9385f7b996a44c50af9aaafe33ef3478","d709a907ff5c463682ab6a4d39cf0df7","6924a8cadb1c47bc89b1482a718069cb","c45ceb8795a043b79af8ae959af46f19","383ef7ba620948af904914a529b31e22","b0e696dc27ce478c918ca9cf920d6fd4","8d71c2638b194173a32eb5cf9ea1638b","986c9b78a1c94c5c9c7372c5414477b0","2ef509d5e632495a995cafaf9e577665","5fe2c50e88ec41bf96df9f6dc1be3110","64b5ffe50f754ca68747df88bb25b3e8","bd385f938dbd48d6a34a4ac75875c334","a46d1ecbbd1f48e5a9c4050af1630c38","f6ba880d1b41478fa859faed6e837dec","fee76f30d2ed4d508de4c63f9523a751","3e66f4e576724d79a5d1f885715ed439","8475e4d21e5c4e8c9e8bd911838884d9","57bce76778e54fea8e36b7eb574066bf","632dfb6bbf2c46be947a404f171fa1ac","eb8231713b73435eb8c094c72f35688f","233e1e6d34304ab38169718ae6cd1c27","6c0bbff742f945be86ed5f4340e696d7","8dc596f4c6c84931be9973ff55c82b3b","4d9e8c816f564dfdacbb49b25115ba28","80533118f03047afb012eb2cf9ccd2dc","b838a1c3f48d4e9d9b24fca97eda0734","94901ac03deb4877b81ae39be0e4aa07","bf33f992cd4b4249abd593742d25c63c","3011925d7e42419eaaaffc692736384a","ba82414c88e1474a8a423d62b4f6dd5c","e519149117c1422186fa1480cbfcc0cb","9b5335f50ec94a7f8fcfc8560d09c322","91fb3b8ed6a74bef8d7e282d5258018b","cd896257a8bc45738e35f6e29582702b","823df13840024e539709bb3c191d1321","3ce8d5c5e6734e62b71322ab8a015722","a92a3fbed5ac47478da98afbac96945a","a78f65fbaa3b4ff094b3697aad367d6c","c8fe4dfb60944b97b25811bd09111c79","b1365a2b98b048a3863ddf8416b43f8f","99c5a3b5dba3446596321119055f077a","3c9bf0694e774c2caa36bcd5ecb88dec","b6a9dc0167f94268a64db211145dcc55","188bf407c104446298ca0688dca78e62","2eda4875ad3d46369408083ff291cddb","e1852b4de1f747088d2bfc225da1a0a2","fe43aa1ca6104b10a3ee8992f5381a24","6eb5d567af1d449e9106bc7a0104ace0","969742237093493aa88d1f968c380a5f","976f1cd642fc474abb3d6e734727db6c","bdd7a0dcb9b9435fa78aec4bfc28cdbb","c9930592e05f4cfaa929d06b04be28df","ecf5bede3d9a4fbea91e867a861db747","d5b852f4fe88478dbb90aef1930671c1","5fbb49c8492a4b2db7cb27f527f7640a","1029c6770daf48fdae2afa15088032fd","724b509a59354c88b76824d8043a345e","df420e65d3dc4c7292006128398b8e3d","9f3c6f283fb04308b7e553a68bcedab3","dd05e21db3854a7ab2c63c27704688f0","3957ecc237b346628cd31516b0cc876a","b4ff452d048a4b4f82848ddfad585668","4e8e535d1eb64a27bc1c941b58d1ad2f","9ea3109c4a8c4442bde5ba9817d86dba","58bf84210cba42a49a009e77a6beff60","86e167db76ca414393b0d3d71cffa5aa","35cc6ca1582d47ef92e37269ac1e8954","a3055dba8c894242bce58e99f83da44c","77f67a24b48c4b28be046f33519d7285","4c8b2549babe411d8407131dd6edb181","54afaf46b3214585ac5142de94bc1889","71883396d0284d59be782aaf8508c557","ef77b9e4f4bf453a8978715cdda81b1c","928a61693af04300850537c42bf85608","033a57c883ac4668bdc4c81f5e0f3ac3","b1958314449842c98d3e315c820110fd","717b6df1a26c4e00a023c647b503a47d","9db77407ad584dd5ad2540c5e0a44a9b","d523d65538a04a479c1f006d5f00d84b","6b8eba7f28a04a5c96dcdc7d6549d619","31b6e9c857bd4e47bc5d6d0d29d7a3f3","07ed0eda200a44238c6154304aeeff75","14085239051840f8ac00e6023a30a6bf","ff2303700e854ffa8db0d66a5c02b97d","3870d5e007be41038ee223db6b6b9bbd","5d8eae1d0f9d4bb2832dd3808b04bcd8","24895308804a4b3ea088f86c5b5fc558","97dd3613afa64298a1b0cdf535d5e90b","d70c7e6551c4409ea0dde17e395075ed","4a616395671446dba51685dc90b8350b","8855f592c3e54a359143c8ee0025eb01","abe647aca34a4cd3a1eed0c2598812d5","716e1cba79c549b797e6afe6d4f57901","62a022a211bc4cd29fd1dc641606d8cd","23e5a082548843679d47d78b6de192c9","81ec7ab636be40809b1395a02be2eb17","3e2dce46c35e42f585c2393697fa1b28","e590189e46324c3d92d957c98302050c","f28f2f667b6b4d3eb427bbde96357fd4","000789e4dc6a43dc820b37630cd3e618","d75260c6904d439b9e7192f54c73ad1f","8e920f0f4fce450b971d62cd96de33e5","6767cbdc885f4beda5b4b43c4747403e","ec47590de3414d0385bc2468368c516c","2edfef5db7f04c358a832272da0b991f","7704cfcdbe3d4fbfb797223ca3480642","72caa023251e47c7b00a4a3655f3d0d5","4989f4feb691484ca32b8b6d306427a4","1f1b371baec9430fa9105416a738a82e","4b61c5e2a2ff4f3babd31fc774a8bd24","9405cb78cb4b444484e84635dcd28661","04364f136ac940709bd6a01a5b920e93","6e57ce2de06f4daa9e8d9a52283ad34d","653b91fb3db84e81a5181cbb37509ed7","65dd3694a1384785a520d66a8b672786","e9625ccfc621456089ca2abb1bb582ba","038c8c1186c4424eabfa652893e6d9c4"]},"id":"r6bUnxe6N3pf","outputId":"d3f62c62-4848-40b1-c828-79d0cdb5a631"},"outputs":[{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/6.76k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b80d2893ca824cbeb394bade07ba379a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["train_prefs-00000-of-00001.parquet:   0%|          | 0.00/226M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"171a028b33554c65a9106cabd65f3e1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["test_prefs-00000-of-00001.parquet:   0%|          | 0.00/7.29M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14d6bbd363574039a16976d872b928dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["test_sft-00000-of-00001.parquet:   0%|          | 0.00/3.72M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c234edacd9e4c24aa5f84c675ece817"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["train_gen-00000-of-00001.parquet:   0%|          | 0.00/184M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"986c9b78a1c94c5c9c7372c5414477b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["test_gen-00000-of-00001.parquet:   0%|          | 0.00/3.02M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"632dfb6bbf2c46be947a404f171fa1ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train_prefs split:   0%|          | 0/61135 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba82414c88e1474a8a423d62b4f6dd5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train_sft split:   0%|          | 0/61135 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99c5a3b5dba3446596321119055f077a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test_prefs split:   0%|          | 0/2000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9930592e05f4cfaa929d06b04be28df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test_sft split:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e8e535d1eb64a27bc1c941b58d1ad2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train_gen split:   0%|          | 0/61135 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"928a61693af04300850537c42bf85608"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test_gen split:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3870d5e007be41038ee223db6b6b9bbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Formatting comparisons with prompt template (num_proc=12):   0%|          | 0/305 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81ec7ab636be40809b1395a02be2eb17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Formatting comparisons with prompt template (num_proc=12):   0%|          | 0/2000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72caa023251e47c7b00a4a3655f3d0d5"}},"metadata":{}}],"source":["raw_datasets = get_datasets(\n","    {\"HuggingFaceH4/ultrafeedback_binarized\" : 0.005}, # 0.5% sampled\n","    splits = [\"train_prefs\", \"test_prefs\"],\n",")\n","column_names = list(raw_datasets[\"train\"].features)\n","\n","raw_datasets = raw_datasets.map(\n","    apply_chat_template,\n","    fn_kwargs = {\"tokenizer\": tokenizer, \"task\": \"dpo\"},\n","    num_proc = 12,\n","    remove_columns = column_names,\n","    desc = \"Formatting comparisons with prompt template\",\n",")\n","\n","# Replace column names with what TRL needs, text_chosen -> chosen and text_rejected -> rejected\n","for split in [\"train\", \"test\"]:\n","    raw_datasets[split] = raw_datasets[split].rename_columns(\n","        {\"text_prompt\": \"prompt\", \"text_chosen\": \"chosen\", \"text_rejected\": \"rejected\"}\n","    )"]},{"cell_type":"markdown","source":["### Print Random Item from Dataset"],"metadata":{"id":"PqHe5zQFL8vQ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oF63zQqNlNJC","outputId":"19fa7cba-5be8-4af2-d614-474a29c29fc3"},"outputs":[{"output_type":"stream","name":"stdout","text":["('<|system|>\\n'\n"," '</s>\\n'\n"," '<|user|>\\n'\n"," 'Describe a possible solution to the environmental issue of air '\n"," 'pollution.</s>\\n'\n"," '<|assistant|>\\n')\n","('One of the most effective solutions to the environmental issue of air '\n"," 'pollution is promoting and investing in renewable energy sources. '\n"," 'Traditional energy sources like coal and oil produce large amounts of '\n"," 'greenhouse gases that contribute greatly to air pollution. Renewable energy '\n"," 'sources like wind, solar, and hydropower sources do not produce greenhouse '\n"," 'gases. They use clean energy sources that do not harm the environment and do '\n"," 'not contribute to air pollution. \\n'\n"," '\\n'\n"," 'Another solution is improving our public transportation systems. Encouraging '\n"," 'individuals to use public transportation, cycling, walking, or carpooling '\n"," 'instead of their personal vehicles can greatly reduce emissions. This is '\n"," 'especially helpful in urban areas where traffic congestion and subsequent '\n"," 'air pollution is a common issue. \\n'\n"," '\\n'\n"," 'Reducing the use of single-use plastics can also be a significant step in '\n"," 'reducing air pollution. The production, transportation, and disposal of '\n"," 'plastic products contributes a large amount to greenhouse gases and air '\n"," 'pollution. Using reusable bags, bottles, and containers can greatly reduce '\n"," 'the amount of plastic waste and in turn, pollution.\\n'\n"," '\\n'\n"," 'Implementing stricter regulations and penalties on industries that heavily '\n"," 'pollute can also be a solution. Cleaner production practices can be '\n"," 'enforced, and those who fail to comply can be penalized, raising awareness '\n"," 'of the consequences of air pollution.\\n'\n"," '\\n'\n"," 'Finally, increasing research and development in clean technologies can lead '\n"," 'to innovative solutions to air pollution. This includes technologies that '\n"," 'remove pollutants from the air, more efficient energy storage systems for '\n"," 'renewable energy, and more effective waste management systems.\\n'\n"," '\\n'\n"," 'These solutions, when implemented in a systematic manner, can go a long way '\n"," 'in reducing air pollution and protecting our environment.</s>\\n')\n","(\"Hello! As a helpful and respectful assistant, I'm here to provide you with \"\n"," 'information and answers that are safe, accurate, and positive. I understand '\n"," \"the importance of addressing environmental issues, and I'm happy to help you \"\n"," 'explore possible solutions to air pollution.\\n'\n"," '\\n'\n"," 'Air pollution is a pressing environmental issue that affects not only the '\n"," 'environment but also human health. It can cause respiratory problems, '\n"," 'cardiovascular diseases, and even cancer. To address this issue, there are '\n"," 'several possible solutions that can be implemented at the individual, '\n"," 'community, and government levels.\\n'\n"," '\\n'\n"," 'One possible solution is to use cleaner energy sources such as wind, solar, '\n"," 'and hydroelectric power. These sources of energy are renewable and produce '\n"," 'minimal air pollution compared to fossil fuels. Additionally, we can reduce '\n"," 'our energy consumption by using energy-efficient appliances and turning off '\n"," 'lights and electronics when not in use.\\n'\n"," '\\n'\n"," 'Another solution is to improve public transportation and encourage the use '\n"," 'of electric or hybrid vehicles. This can reduce the number of cars on the '\n"," 'road, which in turn can reduce air pollution. Governments can also encourage '\n"," 'the use of public transportation by investing in infrastructure and '\n"," 'providing incentives for using eco-friendly vehicles.\\n'\n"," '\\n'\n"," 'Moreover, we can reduce air pollution by reducing waste and properly '\n"," 'disposing of hazardous materials. We can also promote sustainable '\n"," 'agriculture practices that reduce the use of harmful chemicals and promote '\n"," 'soil health.\\n'\n"," '\\n'\n"," \"Lastly, it's important to raise awareness about air pollution and its \"\n"," 'effects on human health and the environment. Education is key to promoting '\n"," 'behavior change and encouraging individuals to take action to reduce air '\n"," 'pollution.\\n'\n"," '\\n'\n"," 'Overall, addressing air pollution requires a multi-faceted approach that '\n"," 'involves individuals, communities, and governments working together. By '\n"," 'implementing these possible solutions, we can work towards creating a '\n"," 'healthier and more sustainable future for all.</s>\\n')\n"]}],"source":["import pprint\n","row = raw_datasets[\"train\"][8]\n","pprint.pprint(row[\"prompt\"])\n","pprint.pprint(row[\"chosen\"])\n","pprint.pprint(row[\"rejected\"])"]},{"cell_type":"markdown","source":["### Add LoRA Adapters\n","We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"],"metadata":{"id":"60IXo6e6L_Bn"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6bZsfBuZDeCL","outputId":"cb53cb5f-969f-4076-8657-337b05ffb783"},"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2024.9.post4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]}],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 64, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 64,\n","    lora_dropout = 0, # Currently only supports dropout = 0\n","    bias = \"none\",    # Currently only supports bias = \"none\"\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"]},{"cell_type":"markdown","metadata":{"id":"-kyd_iyz7DUM"},"source":["### Train the DPO model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v-2BFpDWzo1K"},"outputs":[],"source":["# One must patch the DPO Trainer first!\n","from unsloth import PatchDPOTrainer\n","PatchDPOTrainer()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["7b6f5d182d47481a967491f258ea7725","7bcf0d8a8bbc464ea4ed558b47b62228","e9641762d7b249a984a80b4293f1c321","b4332c14375d4fb08dbb8b1ad05c53a3","bc17cfc861454826a57dd0f6a81c87cb","7f928924cffa4f96bbec1e48554d8394","64caef5eecb2489cb8dd0e662087139d","74a9bb1dd8b5400ab3cd032b996f6306","29f6ff29e1c04e7e963f427cd234d05e","e43861df4df74b199a589d5ff254401d","82db996804534829bd56ecbf40d42e63"]},"id":"QtoqUw80QDV0","outputId":"731964ff-b94c-4455-f390-cb43d00c50d4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Tokenizing train dataset:   0%|          | 0/305 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b6f5d182d47481a967491f258ea7725"}},"metadata":{}}],"source":["from transformers import TrainingArguments\n","from trl import DPOTrainer, DPOConfig\n","from unsloth import is_bfloat16_supported\n","\n","dpo_trainer = DPOTrainer(\n","    model = model,\n","    ref_model = None,\n","    args = DPOConfig(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_ratio = 0.1,\n","        num_train_epochs = 3,\n","        learning_rate = 5e-6,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.0,\n","        lr_scheduler_type = \"linear\",\n","        seed = 42,\n","        output_dir = \"outputs\",\n","    ),\n","    beta = 0.1,\n","    train_dataset = raw_datasets[\"train\"],\n","    # eval_dataset = raw_datasets[\"test\"],\n","    tokenizer = tokenizer,\n","    max_length = 1024,\n","    max_prompt_length = 512,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"EWGFqAo5Q2me","outputId":"15992bfc-4684-4117-ee15-cf8b1195913a"},"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 305 | Num Epochs = 3\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 114\n"," \"-____-\"     Number of trainable parameters = 167,772,160\n","Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [114/114 08:59, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>rewards / chosen</th>\n","      <th>rewards / rejected</th>\n","      <th>rewards / accuracies</th>\n","      <th>rewards / margins</th>\n","      <th>logps / rejected</th>\n","      <th>logps / chosen</th>\n","      <th>logits / rejected</th>\n","      <th>logits / chosen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.693100</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-201.783752</td>\n","      <td>-206.256256</td>\n","      <td>-2.673173</td>\n","      <td>-2.805595</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.693100</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-293.298676</td>\n","      <td>-294.617157</td>\n","      <td>-2.605451</td>\n","      <td>-2.248089</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.671300</td>\n","      <td>-0.001226</td>\n","      <td>-0.045723</td>\n","      <td>0.750000</td>\n","      <td>0.044497</td>\n","      <td>-319.224670</td>\n","      <td>-335.144318</td>\n","      <td>-2.595082</td>\n","      <td>-2.624325</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.697000</td>\n","      <td>-0.015006</td>\n","      <td>-0.008900</td>\n","      <td>0.500000</td>\n","      <td>-0.006106</td>\n","      <td>-318.266510</td>\n","      <td>-248.461868</td>\n","      <td>-2.750491</td>\n","      <td>-2.863873</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.695100</td>\n","      <td>-0.002731</td>\n","      <td>0.000216</td>\n","      <td>0.375000</td>\n","      <td>-0.002947</td>\n","      <td>-230.219543</td>\n","      <td>-206.181808</td>\n","      <td>-2.790885</td>\n","      <td>-2.672144</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.692100</td>\n","      <td>-0.008549</td>\n","      <td>-0.011130</td>\n","      <td>0.500000</td>\n","      <td>0.002581</td>\n","      <td>-412.195312</td>\n","      <td>-388.119049</td>\n","      <td>-2.898546</td>\n","      <td>-2.860778</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.682900</td>\n","      <td>-0.007663</td>\n","      <td>-0.028559</td>\n","      <td>0.750000</td>\n","      <td>0.020896</td>\n","      <td>-340.921478</td>\n","      <td>-238.065155</td>\n","      <td>-2.744619</td>\n","      <td>-2.748619</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.705000</td>\n","      <td>-0.062952</td>\n","      <td>-0.040059</td>\n","      <td>0.375000</td>\n","      <td>-0.022893</td>\n","      <td>-271.702881</td>\n","      <td>-163.249725</td>\n","      <td>-2.424583</td>\n","      <td>-2.383191</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.693500</td>\n","      <td>-0.025499</td>\n","      <td>-0.027195</td>\n","      <td>0.500000</td>\n","      <td>0.001696</td>\n","      <td>-214.502594</td>\n","      <td>-296.540039</td>\n","      <td>-2.542014</td>\n","      <td>-2.869443</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.676200</td>\n","      <td>-0.008218</td>\n","      <td>-0.044155</td>\n","      <td>0.750000</td>\n","      <td>0.035936</td>\n","      <td>-268.547974</td>\n","      <td>-363.621887</td>\n","      <td>-2.792253</td>\n","      <td>-3.169026</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.666700</td>\n","      <td>-0.014119</td>\n","      <td>-0.068602</td>\n","      <td>0.750000</td>\n","      <td>0.054484</td>\n","      <td>-281.862640</td>\n","      <td>-266.179260</td>\n","      <td>-2.751250</td>\n","      <td>-2.581418</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.678100</td>\n","      <td>-0.046890</td>\n","      <td>-0.080301</td>\n","      <td>0.875000</td>\n","      <td>0.033412</td>\n","      <td>-340.948730</td>\n","      <td>-438.813354</td>\n","      <td>-2.371463</td>\n","      <td>-2.135303</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.685800</td>\n","      <td>-0.054941</td>\n","      <td>-0.073158</td>\n","      <td>0.625000</td>\n","      <td>0.018217</td>\n","      <td>-367.868408</td>\n","      <td>-271.939484</td>\n","      <td>-2.836360</td>\n","      <td>-2.441061</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.674500</td>\n","      <td>0.003049</td>\n","      <td>-0.036229</td>\n","      <td>0.625000</td>\n","      <td>0.039278</td>\n","      <td>-196.535187</td>\n","      <td>-291.457092</td>\n","      <td>-2.521554</td>\n","      <td>-2.838106</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.618600</td>\n","      <td>-0.073614</td>\n","      <td>-0.231173</td>\n","      <td>0.875000</td>\n","      <td>0.157559</td>\n","      <td>-362.204193</td>\n","      <td>-233.810089</td>\n","      <td>-2.813243</td>\n","      <td>-2.755177</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.621000</td>\n","      <td>-0.122374</td>\n","      <td>-0.282143</td>\n","      <td>0.750000</td>\n","      <td>0.159768</td>\n","      <td>-371.639923</td>\n","      <td>-359.530212</td>\n","      <td>-2.396964</td>\n","      <td>-2.511785</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.648000</td>\n","      <td>-0.062182</td>\n","      <td>-0.170860</td>\n","      <td>0.500000</td>\n","      <td>0.108678</td>\n","      <td>-321.299774</td>\n","      <td>-320.223724</td>\n","      <td>-2.761248</td>\n","      <td>-2.805582</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.615200</td>\n","      <td>-0.046531</td>\n","      <td>-0.221549</td>\n","      <td>0.750000</td>\n","      <td>0.175018</td>\n","      <td>-403.215942</td>\n","      <td>-419.167999</td>\n","      <td>-2.919084</td>\n","      <td>-3.033377</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.684000</td>\n","      <td>-0.068287</td>\n","      <td>-0.109373</td>\n","      <td>0.625000</td>\n","      <td>0.041086</td>\n","      <td>-294.350769</td>\n","      <td>-275.750885</td>\n","      <td>-2.899297</td>\n","      <td>-2.775954</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.551900</td>\n","      <td>-0.186825</td>\n","      <td>-0.527251</td>\n","      <td>1.000000</td>\n","      <td>0.340426</td>\n","      <td>-380.538666</td>\n","      <td>-228.589554</td>\n","      <td>-2.606213</td>\n","      <td>-2.398477</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.611200</td>\n","      <td>-0.058906</td>\n","      <td>-0.249551</td>\n","      <td>0.750000</td>\n","      <td>0.190645</td>\n","      <td>-353.962189</td>\n","      <td>-291.419525</td>\n","      <td>-2.575001</td>\n","      <td>-2.119922</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.599000</td>\n","      <td>-0.196948</td>\n","      <td>-0.406260</td>\n","      <td>0.875000</td>\n","      <td>0.209312</td>\n","      <td>-328.265839</td>\n","      <td>-243.086227</td>\n","      <td>-2.346888</td>\n","      <td>-2.539586</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.639200</td>\n","      <td>-0.150476</td>\n","      <td>-0.281819</td>\n","      <td>0.625000</td>\n","      <td>0.131343</td>\n","      <td>-280.466064</td>\n","      <td>-273.044342</td>\n","      <td>-2.607422</td>\n","      <td>-2.746234</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.645300</td>\n","      <td>-0.269015</td>\n","      <td>-0.374027</td>\n","      <td>0.750000</td>\n","      <td>0.105012</td>\n","      <td>-158.409897</td>\n","      <td>-169.919235</td>\n","      <td>-2.756578</td>\n","      <td>-2.844643</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.530400</td>\n","      <td>-0.243887</td>\n","      <td>-0.647068</td>\n","      <td>0.875000</td>\n","      <td>0.403181</td>\n","      <td>-314.649170</td>\n","      <td>-400.331421</td>\n","      <td>-2.754964</td>\n","      <td>-2.729400</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.550700</td>\n","      <td>-0.125732</td>\n","      <td>-0.487171</td>\n","      <td>0.875000</td>\n","      <td>0.361438</td>\n","      <td>-400.001495</td>\n","      <td>-246.451340</td>\n","      <td>-2.667126</td>\n","      <td>-2.689138</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.508200</td>\n","      <td>-0.137124</td>\n","      <td>-0.589117</td>\n","      <td>0.875000</td>\n","      <td>0.451994</td>\n","      <td>-347.203430</td>\n","      <td>-376.321533</td>\n","      <td>-2.703793</td>\n","      <td>-2.569561</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.470100</td>\n","      <td>-0.255506</td>\n","      <td>-0.838154</td>\n","      <td>0.875000</td>\n","      <td>0.582648</td>\n","      <td>-353.608276</td>\n","      <td>-359.571747</td>\n","      <td>-2.313169</td>\n","      <td>-2.159135</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.501000</td>\n","      <td>-0.340685</td>\n","      <td>-0.904409</td>\n","      <td>0.750000</td>\n","      <td>0.563724</td>\n","      <td>-463.133850</td>\n","      <td>-336.919128</td>\n","      <td>-2.891499</td>\n","      <td>-2.976351</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.412600</td>\n","      <td>0.166774</td>\n","      <td>-0.573554</td>\n","      <td>0.875000</td>\n","      <td>0.740327</td>\n","      <td>-351.773193</td>\n","      <td>-415.290894</td>\n","      <td>-3.054593</td>\n","      <td>-2.894500</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.683300</td>\n","      <td>-0.330283</td>\n","      <td>-0.416570</td>\n","      <td>0.375000</td>\n","      <td>0.086287</td>\n","      <td>-211.546173</td>\n","      <td>-205.074615</td>\n","      <td>-2.605298</td>\n","      <td>-2.768109</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.521000</td>\n","      <td>-0.239722</td>\n","      <td>-0.656228</td>\n","      <td>0.750000</td>\n","      <td>0.416506</td>\n","      <td>-340.341400</td>\n","      <td>-208.105133</td>\n","      <td>-2.261404</td>\n","      <td>-2.139565</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.440100</td>\n","      <td>0.159992</td>\n","      <td>-0.616174</td>\n","      <td>0.625000</td>\n","      <td>0.776166</td>\n","      <td>-355.379944</td>\n","      <td>-263.010284</td>\n","      <td>-2.573785</td>\n","      <td>-2.408968</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.487200</td>\n","      <td>-0.232112</td>\n","      <td>-0.919933</td>\n","      <td>0.750000</td>\n","      <td>0.687821</td>\n","      <td>-382.629578</td>\n","      <td>-271.467560</td>\n","      <td>-2.944986</td>\n","      <td>-2.928241</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.442100</td>\n","      <td>-0.079193</td>\n","      <td>-0.765647</td>\n","      <td>0.875000</td>\n","      <td>0.686454</td>\n","      <td>-291.545410</td>\n","      <td>-261.491058</td>\n","      <td>-2.204849</td>\n","      <td>-2.224172</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.583400</td>\n","      <td>-0.624320</td>\n","      <td>-1.033669</td>\n","      <td>0.625000</td>\n","      <td>0.409349</td>\n","      <td>-395.623749</td>\n","      <td>-390.940369</td>\n","      <td>-2.584045</td>\n","      <td>-3.007868</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.672800</td>\n","      <td>-0.472653</td>\n","      <td>-0.825816</td>\n","      <td>0.500000</td>\n","      <td>0.353162</td>\n","      <td>-352.160278</td>\n","      <td>-284.742493</td>\n","      <td>-2.236471</td>\n","      <td>-2.505338</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.435400</td>\n","      <td>-0.282128</td>\n","      <td>-1.024585</td>\n","      <td>0.875000</td>\n","      <td>0.742457</td>\n","      <td>-294.012451</td>\n","      <td>-217.030731</td>\n","      <td>-2.775206</td>\n","      <td>-2.737626</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.248400</td>\n","      <td>-0.139606</td>\n","      <td>-2.023705</td>\n","      <td>0.875000</td>\n","      <td>1.884099</td>\n","      <td>-375.991455</td>\n","      <td>-301.029388</td>\n","      <td>-3.085306</td>\n","      <td>-2.954212</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.223900</td>\n","      <td>0.174192</td>\n","      <td>-2.197203</td>\n","      <td>1.000000</td>\n","      <td>2.371395</td>\n","      <td>-339.189911</td>\n","      <td>-258.237427</td>\n","      <td>-2.762352</td>\n","      <td>-2.627617</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.184100</td>\n","      <td>-0.118083</td>\n","      <td>-1.784477</td>\n","      <td>1.000000</td>\n","      <td>1.666394</td>\n","      <td>-387.075500</td>\n","      <td>-284.464905</td>\n","      <td>-2.690324</td>\n","      <td>-2.711376</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.241100</td>\n","      <td>-0.091149</td>\n","      <td>-1.750886</td>\n","      <td>1.000000</td>\n","      <td>1.659737</td>\n","      <td>-336.811493</td>\n","      <td>-411.275055</td>\n","      <td>-2.779717</td>\n","      <td>-2.795004</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.224900</td>\n","      <td>0.218270</td>\n","      <td>-1.719341</td>\n","      <td>1.000000</td>\n","      <td>1.937611</td>\n","      <td>-200.266815</td>\n","      <td>-134.864853</td>\n","      <td>-2.988652</td>\n","      <td>-2.898535</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.160000</td>\n","      <td>-0.163389</td>\n","      <td>-2.447133</td>\n","      <td>1.000000</td>\n","      <td>2.283744</td>\n","      <td>-287.539124</td>\n","      <td>-174.697662</td>\n","      <td>-2.516340</td>\n","      <td>-2.287175</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.262300</td>\n","      <td>-0.210916</td>\n","      <td>-1.781716</td>\n","      <td>1.000000</td>\n","      <td>1.570800</td>\n","      <td>-429.366028</td>\n","      <td>-374.386169</td>\n","      <td>-2.127144</td>\n","      <td>-2.074291</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.201000</td>\n","      <td>-0.459106</td>\n","      <td>-2.452207</td>\n","      <td>0.875000</td>\n","      <td>1.993101</td>\n","      <td>-394.777649</td>\n","      <td>-392.489563</td>\n","      <td>-2.892111</td>\n","      <td>-2.796068</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.174500</td>\n","      <td>0.057698</td>\n","      <td>-1.937762</td>\n","      <td>1.000000</td>\n","      <td>1.995459</td>\n","      <td>-300.787445</td>\n","      <td>-325.520447</td>\n","      <td>-2.560457</td>\n","      <td>-2.528769</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.299800</td>\n","      <td>-0.505098</td>\n","      <td>-1.872469</td>\n","      <td>0.875000</td>\n","      <td>1.367371</td>\n","      <td>-326.271667</td>\n","      <td>-318.079834</td>\n","      <td>-3.031414</td>\n","      <td>-2.849027</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.173700</td>\n","      <td>-0.105468</td>\n","      <td>-2.841405</td>\n","      <td>0.875000</td>\n","      <td>2.735938</td>\n","      <td>-361.021484</td>\n","      <td>-366.450439</td>\n","      <td>-2.778554</td>\n","      <td>-2.639332</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.287500</td>\n","      <td>0.041483</td>\n","      <td>-1.518132</td>\n","      <td>0.750000</td>\n","      <td>1.559615</td>\n","      <td>-216.450623</td>\n","      <td>-151.746063</td>\n","      <td>-2.330930</td>\n","      <td>-2.314308</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.277100</td>\n","      <td>-0.264578</td>\n","      <td>-2.097855</td>\n","      <td>0.875000</td>\n","      <td>1.833277</td>\n","      <td>-337.513245</td>\n","      <td>-279.822601</td>\n","      <td>-2.781894</td>\n","      <td>-2.900168</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.235200</td>\n","      <td>-0.203761</td>\n","      <td>-2.089465</td>\n","      <td>1.000000</td>\n","      <td>1.885704</td>\n","      <td>-278.868622</td>\n","      <td>-245.772110</td>\n","      <td>-2.534986</td>\n","      <td>-2.491330</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.076200</td>\n","      <td>0.190007</td>\n","      <td>-3.185058</td>\n","      <td>1.000000</td>\n","      <td>3.375066</td>\n","      <td>-368.676666</td>\n","      <td>-263.749451</td>\n","      <td>-2.624402</td>\n","      <td>-2.429501</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.264400</td>\n","      <td>-0.353757</td>\n","      <td>-2.341198</td>\n","      <td>0.875000</td>\n","      <td>1.987441</td>\n","      <td>-375.989807</td>\n","      <td>-418.137726</td>\n","      <td>-2.958995</td>\n","      <td>-2.926175</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.159700</td>\n","      <td>-0.316914</td>\n","      <td>-2.565899</td>\n","      <td>1.000000</td>\n","      <td>2.248985</td>\n","      <td>-328.590515</td>\n","      <td>-383.295502</td>\n","      <td>-2.562612</td>\n","      <td>-2.834299</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.242700</td>\n","      <td>-0.585094</td>\n","      <td>-2.546159</td>\n","      <td>0.875000</td>\n","      <td>1.961065</td>\n","      <td>-349.156158</td>\n","      <td>-354.892822</td>\n","      <td>-2.888003</td>\n","      <td>-3.042670</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.150700</td>\n","      <td>-0.490949</td>\n","      <td>-2.925945</td>\n","      <td>1.000000</td>\n","      <td>2.434996</td>\n","      <td>-268.767487</td>\n","      <td>-211.759262</td>\n","      <td>-1.710422</td>\n","      <td>-1.760566</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.217900</td>\n","      <td>-0.222974</td>\n","      <td>-2.039958</td>\n","      <td>1.000000</td>\n","      <td>1.816984</td>\n","      <td>-503.069824</td>\n","      <td>-358.240967</td>\n","      <td>-2.599180</td>\n","      <td>-2.668892</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.212800</td>\n","      <td>-0.609828</td>\n","      <td>-2.885329</td>\n","      <td>0.875000</td>\n","      <td>2.275501</td>\n","      <td>-281.150208</td>\n","      <td>-191.983231</td>\n","      <td>-2.363167</td>\n","      <td>-2.180810</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.254000</td>\n","      <td>-0.584402</td>\n","      <td>-3.001188</td>\n","      <td>0.875000</td>\n","      <td>2.416786</td>\n","      <td>-394.474640</td>\n","      <td>-244.409637</td>\n","      <td>-2.966942</td>\n","      <td>-2.759922</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>0.102100</td>\n","      <td>-0.100118</td>\n","      <td>-2.528394</td>\n","      <td>1.000000</td>\n","      <td>2.428276</td>\n","      <td>-317.839203</td>\n","      <td>-291.435852</td>\n","      <td>-2.386817</td>\n","      <td>-2.411813</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>0.236700</td>\n","      <td>-0.295110</td>\n","      <td>-2.349425</td>\n","      <td>0.875000</td>\n","      <td>2.054315</td>\n","      <td>-369.208221</td>\n","      <td>-211.296234</td>\n","      <td>-2.525635</td>\n","      <td>-2.537556</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>0.194000</td>\n","      <td>-0.060794</td>\n","      <td>-2.045748</td>\n","      <td>0.875000</td>\n","      <td>1.984954</td>\n","      <td>-242.979553</td>\n","      <td>-244.631775</td>\n","      <td>-2.511292</td>\n","      <td>-2.569170</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>0.335500</td>\n","      <td>-0.462116</td>\n","      <td>-1.924202</td>\n","      <td>0.875000</td>\n","      <td>1.462086</td>\n","      <td>-252.358368</td>\n","      <td>-295.855469</td>\n","      <td>-2.288504</td>\n","      <td>-2.666375</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.252800</td>\n","      <td>-0.771137</td>\n","      <td>-2.910534</td>\n","      <td>1.000000</td>\n","      <td>2.139397</td>\n","      <td>-480.578003</td>\n","      <td>-281.541992</td>\n","      <td>-2.815485</td>\n","      <td>-2.857982</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>0.250900</td>\n","      <td>0.101049</td>\n","      <td>-2.216239</td>\n","      <td>0.875000</td>\n","      <td>2.317289</td>\n","      <td>-308.199646</td>\n","      <td>-256.201630</td>\n","      <td>-2.519602</td>\n","      <td>-2.595135</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>0.412200</td>\n","      <td>-0.693424</td>\n","      <td>-2.527977</td>\n","      <td>0.875000</td>\n","      <td>1.834553</td>\n","      <td>-460.831116</td>\n","      <td>-340.358704</td>\n","      <td>-2.860075</td>\n","      <td>-2.836818</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>0.125500</td>\n","      <td>-0.423279</td>\n","      <td>-2.856764</td>\n","      <td>1.000000</td>\n","      <td>2.433486</td>\n","      <td>-287.633209</td>\n","      <td>-251.213181</td>\n","      <td>-2.732173</td>\n","      <td>-2.674181</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>0.181800</td>\n","      <td>-0.695571</td>\n","      <td>-2.539897</td>\n","      <td>1.000000</td>\n","      <td>1.844326</td>\n","      <td>-368.653656</td>\n","      <td>-339.977478</td>\n","      <td>-2.800088</td>\n","      <td>-2.904078</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.108100</td>\n","      <td>-0.048338</td>\n","      <td>-2.636522</td>\n","      <td>1.000000</td>\n","      <td>2.588184</td>\n","      <td>-325.308716</td>\n","      <td>-374.570435</td>\n","      <td>-2.361522</td>\n","      <td>-2.577637</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>0.138600</td>\n","      <td>-0.248713</td>\n","      <td>-3.595494</td>\n","      <td>0.875000</td>\n","      <td>3.346781</td>\n","      <td>-442.389557</td>\n","      <td>-416.885498</td>\n","      <td>-2.995314</td>\n","      <td>-2.759557</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>0.242500</td>\n","      <td>-0.433165</td>\n","      <td>-2.520571</td>\n","      <td>0.875000</td>\n","      <td>2.087406</td>\n","      <td>-451.552246</td>\n","      <td>-306.169922</td>\n","      <td>-3.041037</td>\n","      <td>-2.740414</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>0.179700</td>\n","      <td>-0.247103</td>\n","      <td>-2.054767</td>\n","      <td>1.000000</td>\n","      <td>1.807664</td>\n","      <td>-313.207245</td>\n","      <td>-297.193604</td>\n","      <td>-2.361151</td>\n","      <td>-2.496202</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>0.211100</td>\n","      <td>-0.236319</td>\n","      <td>-2.143415</td>\n","      <td>1.000000</td>\n","      <td>1.907096</td>\n","      <td>-199.791855</td>\n","      <td>-266.390686</td>\n","      <td>-2.229056</td>\n","      <td>-2.393696</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.127800</td>\n","      <td>-0.252290</td>\n","      <td>-2.776734</td>\n","      <td>1.000000</td>\n","      <td>2.524443</td>\n","      <td>-344.053467</td>\n","      <td>-254.998962</td>\n","      <td>-2.531181</td>\n","      <td>-2.447460</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>0.108300</td>\n","      <td>-0.616473</td>\n","      <td>-3.235550</td>\n","      <td>1.000000</td>\n","      <td>2.619077</td>\n","      <td>-292.125732</td>\n","      <td>-195.777069</td>\n","      <td>-2.421279</td>\n","      <td>-2.589159</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>0.043500</td>\n","      <td>0.407960</td>\n","      <td>-3.702035</td>\n","      <td>1.000000</td>\n","      <td>4.109995</td>\n","      <td>-365.268005</td>\n","      <td>-356.054810</td>\n","      <td>-2.038300</td>\n","      <td>-2.253193</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>0.042000</td>\n","      <td>-0.781457</td>\n","      <td>-4.078062</td>\n","      <td>1.000000</td>\n","      <td>3.296605</td>\n","      <td>-362.192444</td>\n","      <td>-271.381287</td>\n","      <td>-2.460244</td>\n","      <td>-2.722185</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>0.051700</td>\n","      <td>0.002407</td>\n","      <td>-3.077909</td>\n","      <td>1.000000</td>\n","      <td>3.080317</td>\n","      <td>-414.132751</td>\n","      <td>-290.197083</td>\n","      <td>-2.596683</td>\n","      <td>-2.824401</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.074900</td>\n","      <td>-0.185088</td>\n","      <td>-3.026856</td>\n","      <td>1.000000</td>\n","      <td>2.841768</td>\n","      <td>-274.746490</td>\n","      <td>-349.186218</td>\n","      <td>-2.783105</td>\n","      <td>-2.801142</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>0.208400</td>\n","      <td>-0.319745</td>\n","      <td>-2.314512</td>\n","      <td>0.875000</td>\n","      <td>1.994767</td>\n","      <td>-346.346771</td>\n","      <td>-383.343079</td>\n","      <td>-2.881143</td>\n","      <td>-2.908620</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>0.034500</td>\n","      <td>-0.181863</td>\n","      <td>-4.777534</td>\n","      <td>1.000000</td>\n","      <td>4.595672</td>\n","      <td>-375.294250</td>\n","      <td>-285.762421</td>\n","      <td>-2.838693</td>\n","      <td>-2.656641</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>0.124100</td>\n","      <td>0.017443</td>\n","      <td>-2.464537</td>\n","      <td>1.000000</td>\n","      <td>2.481979</td>\n","      <td>-208.711563</td>\n","      <td>-308.785339</td>\n","      <td>-2.421951</td>\n","      <td>-2.797078</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>0.034600</td>\n","      <td>-0.506409</td>\n","      <td>-4.153473</td>\n","      <td>1.000000</td>\n","      <td>3.647065</td>\n","      <td>-357.768036</td>\n","      <td>-415.144897</td>\n","      <td>-2.864236</td>\n","      <td>-2.817956</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>0.127300</td>\n","      <td>-0.233231</td>\n","      <td>-2.726415</td>\n","      <td>1.000000</td>\n","      <td>2.493184</td>\n","      <td>-265.190247</td>\n","      <td>-193.706619</td>\n","      <td>-2.586719</td>\n","      <td>-2.739814</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>0.079500</td>\n","      <td>-0.455779</td>\n","      <td>-3.539977</td>\n","      <td>1.000000</td>\n","      <td>3.084198</td>\n","      <td>-418.594604</td>\n","      <td>-303.388641</td>\n","      <td>-2.189991</td>\n","      <td>-2.132116</td>\n","    </tr>\n","    <tr>\n","      <td>87</td>\n","      <td>0.083300</td>\n","      <td>-0.020360</td>\n","      <td>-2.852722</td>\n","      <td>1.000000</td>\n","      <td>2.832362</td>\n","      <td>-348.466431</td>\n","      <td>-326.776459</td>\n","      <td>-2.538438</td>\n","      <td>-2.903406</td>\n","    </tr>\n","    <tr>\n","      <td>88</td>\n","      <td>0.056000</td>\n","      <td>-0.235656</td>\n","      <td>-4.020369</td>\n","      <td>1.000000</td>\n","      <td>3.784713</td>\n","      <td>-304.806824</td>\n","      <td>-242.774506</td>\n","      <td>-2.888986</td>\n","      <td>-2.811546</td>\n","    </tr>\n","    <tr>\n","      <td>89</td>\n","      <td>0.059500</td>\n","      <td>-0.738039</td>\n","      <td>-3.971580</td>\n","      <td>1.000000</td>\n","      <td>3.233541</td>\n","      <td>-218.416992</td>\n","      <td>-242.427521</td>\n","      <td>-2.185545</td>\n","      <td>-2.336407</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.084400</td>\n","      <td>-0.426234</td>\n","      <td>-3.807216</td>\n","      <td>1.000000</td>\n","      <td>3.380982</td>\n","      <td>-264.049957</td>\n","      <td>-235.362717</td>\n","      <td>-2.851331</td>\n","      <td>-2.641155</td>\n","    </tr>\n","    <tr>\n","      <td>91</td>\n","      <td>0.031500</td>\n","      <td>-0.357613</td>\n","      <td>-4.063984</td>\n","      <td>1.000000</td>\n","      <td>3.706372</td>\n","      <td>-445.065216</td>\n","      <td>-426.495575</td>\n","      <td>-2.938742</td>\n","      <td>-2.670058</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>0.051300</td>\n","      <td>-0.643525</td>\n","      <td>-4.327811</td>\n","      <td>1.000000</td>\n","      <td>3.684286</td>\n","      <td>-497.358063</td>\n","      <td>-272.079865</td>\n","      <td>-2.821022</td>\n","      <td>-2.508166</td>\n","    </tr>\n","    <tr>\n","      <td>93</td>\n","      <td>0.073400</td>\n","      <td>-0.207134</td>\n","      <td>-3.908080</td>\n","      <td>1.000000</td>\n","      <td>3.700945</td>\n","      <td>-436.585876</td>\n","      <td>-277.535980</td>\n","      <td>-2.944238</td>\n","      <td>-3.082454</td>\n","    </tr>\n","    <tr>\n","      <td>94</td>\n","      <td>0.066300</td>\n","      <td>0.211456</td>\n","      <td>-2.676009</td>\n","      <td>1.000000</td>\n","      <td>2.887465</td>\n","      <td>-394.675110</td>\n","      <td>-336.457733</td>\n","      <td>-3.049045</td>\n","      <td>-2.984406</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>0.051800</td>\n","      <td>0.048777</td>\n","      <td>-3.368889</td>\n","      <td>1.000000</td>\n","      <td>3.417665</td>\n","      <td>-375.346436</td>\n","      <td>-346.208191</td>\n","      <td>-2.720839</td>\n","      <td>-2.736750</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>0.071100</td>\n","      <td>0.020260</td>\n","      <td>-3.110540</td>\n","      <td>1.000000</td>\n","      <td>3.130801</td>\n","      <td>-404.611877</td>\n","      <td>-417.943176</td>\n","      <td>-2.577673</td>\n","      <td>-2.747581</td>\n","    </tr>\n","    <tr>\n","      <td>97</td>\n","      <td>0.131600</td>\n","      <td>-0.498201</td>\n","      <td>-3.679635</td>\n","      <td>0.875000</td>\n","      <td>3.181433</td>\n","      <td>-280.204498</td>\n","      <td>-249.452362</td>\n","      <td>-2.337659</td>\n","      <td>-2.123338</td>\n","    </tr>\n","    <tr>\n","      <td>98</td>\n","      <td>0.038000</td>\n","      <td>0.136231</td>\n","      <td>-3.645748</td>\n","      <td>1.000000</td>\n","      <td>3.781979</td>\n","      <td>-336.118530</td>\n","      <td>-255.503876</td>\n","      <td>-2.393530</td>\n","      <td>-2.405831</td>\n","    </tr>\n","    <tr>\n","      <td>99</td>\n","      <td>0.106500</td>\n","      <td>-0.529723</td>\n","      <td>-3.777123</td>\n","      <td>1.000000</td>\n","      <td>3.247400</td>\n","      <td>-325.296600</td>\n","      <td>-236.567505</td>\n","      <td>-2.332391</td>\n","      <td>-2.039956</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.052200</td>\n","      <td>0.182747</td>\n","      <td>-3.572394</td>\n","      <td>1.000000</td>\n","      <td>3.755142</td>\n","      <td>-371.485840</td>\n","      <td>-358.148987</td>\n","      <td>-2.624187</td>\n","      <td>-2.616088</td>\n","    </tr>\n","    <tr>\n","      <td>101</td>\n","      <td>0.036500</td>\n","      <td>-0.464243</td>\n","      <td>-4.426286</td>\n","      <td>1.000000</td>\n","      <td>3.962043</td>\n","      <td>-502.738434</td>\n","      <td>-326.039062</td>\n","      <td>-2.223864</td>\n","      <td>-2.147664</td>\n","    </tr>\n","    <tr>\n","      <td>102</td>\n","      <td>0.055600</td>\n","      <td>-0.145857</td>\n","      <td>-3.411461</td>\n","      <td>1.000000</td>\n","      <td>3.265604</td>\n","      <td>-340.744476</td>\n","      <td>-283.778503</td>\n","      <td>-2.798217</td>\n","      <td>-2.548160</td>\n","    </tr>\n","    <tr>\n","      <td>103</td>\n","      <td>0.095000</td>\n","      <td>-0.200495</td>\n","      <td>-3.750004</td>\n","      <td>1.000000</td>\n","      <td>3.549510</td>\n","      <td>-247.302460</td>\n","      <td>-224.317474</td>\n","      <td>-2.382216</td>\n","      <td>-2.245982</td>\n","    </tr>\n","    <tr>\n","      <td>104</td>\n","      <td>0.087300</td>\n","      <td>-0.377550</td>\n","      <td>-3.681967</td>\n","      <td>1.000000</td>\n","      <td>3.304418</td>\n","      <td>-376.535339</td>\n","      <td>-248.648972</td>\n","      <td>-2.821337</td>\n","      <td>-2.961335</td>\n","    </tr>\n","    <tr>\n","      <td>105</td>\n","      <td>0.038600</td>\n","      <td>0.024448</td>\n","      <td>-4.853448</td>\n","      <td>1.000000</td>\n","      <td>4.877896</td>\n","      <td>-524.681946</td>\n","      <td>-365.252747</td>\n","      <td>-2.430772</td>\n","      <td>-2.385545</td>\n","    </tr>\n","    <tr>\n","      <td>106</td>\n","      <td>0.112700</td>\n","      <td>0.052868</td>\n","      <td>-3.755341</td>\n","      <td>0.875000</td>\n","      <td>3.808209</td>\n","      <td>-347.886658</td>\n","      <td>-177.068604</td>\n","      <td>-2.181887</td>\n","      <td>-2.087615</td>\n","    </tr>\n","    <tr>\n","      <td>107</td>\n","      <td>0.066400</td>\n","      <td>-0.397443</td>\n","      <td>-3.847058</td>\n","      <td>1.000000</td>\n","      <td>3.449615</td>\n","      <td>-327.035339</td>\n","      <td>-291.748413</td>\n","      <td>-2.416432</td>\n","      <td>-2.236038</td>\n","    </tr>\n","    <tr>\n","      <td>108</td>\n","      <td>0.035300</td>\n","      <td>-0.312439</td>\n","      <td>-5.003975</td>\n","      <td>1.000000</td>\n","      <td>4.691536</td>\n","      <td>-384.539246</td>\n","      <td>-136.221527</td>\n","      <td>-2.366251</td>\n","      <td>-2.598478</td>\n","    </tr>\n","    <tr>\n","      <td>109</td>\n","      <td>0.080500</td>\n","      <td>-0.038344</td>\n","      <td>-3.867736</td>\n","      <td>1.000000</td>\n","      <td>3.829393</td>\n","      <td>-352.434692</td>\n","      <td>-319.255676</td>\n","      <td>-2.135606</td>\n","      <td>-2.347244</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.111500</td>\n","      <td>-0.462345</td>\n","      <td>-3.737737</td>\n","      <td>1.000000</td>\n","      <td>3.275392</td>\n","      <td>-273.133026</td>\n","      <td>-204.775833</td>\n","      <td>-2.035306</td>\n","      <td>-1.889485</td>\n","    </tr>\n","    <tr>\n","      <td>111</td>\n","      <td>0.032900</td>\n","      <td>-0.585463</td>\n","      <td>-5.300733</td>\n","      <td>1.000000</td>\n","      <td>4.715270</td>\n","      <td>-437.759705</td>\n","      <td>-240.147202</td>\n","      <td>-2.592868</td>\n","      <td>-2.804019</td>\n","    </tr>\n","    <tr>\n","      <td>112</td>\n","      <td>0.085700</td>\n","      <td>-0.279214</td>\n","      <td>-3.411724</td>\n","      <td>1.000000</td>\n","      <td>3.132510</td>\n","      <td>-293.442261</td>\n","      <td>-263.934845</td>\n","      <td>-2.490229</td>\n","      <td>-2.472198</td>\n","    </tr>\n","    <tr>\n","      <td>113</td>\n","      <td>0.111500</td>\n","      <td>-0.329615</td>\n","      <td>-2.997323</td>\n","      <td>1.000000</td>\n","      <td>2.667709</td>\n","      <td>-346.890930</td>\n","      <td>-330.004852</td>\n","      <td>-2.718312</td>\n","      <td>-2.777532</td>\n","    </tr>\n","    <tr>\n","      <td>114</td>\n","      <td>0.144600</td>\n","      <td>-1.079301</td>\n","      <td>-4.523984</td>\n","      <td>1.000000</td>\n","      <td>3.444683</td>\n","      <td>-310.137024</td>\n","      <td>-313.563293</td>\n","      <td>-2.313775</td>\n","      <td>-2.592492</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=114, training_loss=0.2976091424362701, metrics={'train_runtime': 549.3662, 'train_samples_per_second': 1.666, 'train_steps_per_second': 0.208, 'total_flos': 0.0, 'train_loss': 0.2976091424362701, 'epoch': 2.980392156862745})"]},"metadata":{},"execution_count":11}],"source":["dpo_trainer.train()"]},{"cell_type":"markdown","source":["## ORPOR Unsloth Example"],"metadata":{"id":"nHt1jnXILlz0"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281,"referenced_widgets":["4a8e18b5a9a54997b850e68041e66eb3","029de2917a324c96b98036ef459c8c70","3f7fd602b7434ca6b58d6ff3306684c0","405af2c924024c0c861c4627e39ca207","77a5f51bd6214f9f98d32c09a0ca6895","acb6b17e625d448dba19fada52d5257f","2c8d4a3ba92e4357bf5b9a4f4641fc8c","fed4ce3c43aa477296b8ce523780a4af","dfe851316a464f6c85b9a5d3d3525a21","840bd9360296400faad8f8ea53ee62ed","364af6723ab44d2cad541f4d2803a8f0","d9a5e05cd4914e959584e8191ed53ac2","55d2e2250f58436d9d9a2ef0d40456d6","4d236a1257554a78b9ecde621916d328","de69489228f9475fb54459f6380ea14e","b9960fc8397845838056ee1f5f6fded5","ffbb43277a06474584787527b8ba0b3e","40a7d93908f84cd882fd26c6dbe88d0c","25a1a7c749df4d15bed8167bd0f74f34","77c92560d54946ba89639a81f67727ca","57dca9909ed64ff983639d64d92bee23","0cbd218a11f443fd8167ecbb34fb8c27","3bf321d40bad4b2f8417d923f6f250dc","8e0efac2ff1248b2b8738b9fa0184d31","d6f2377856254bf29d455f1f37b42a06","70a4a432af0841c09fe6c7abcbacb270","4ade12f4176e4c9da467ef1c2504d07f","fd2c8e91118d4ad99c0619e2ae9d3b1d","691e56ab4f8448ef94a9e2fbe6b4fd64","93080a858eb843d0bbdacd32b88b0d41","ece3b1b4254a414385aa367b34efcc52","c46ce50504464ba3a3a8fb3d7530f928","cde803b0bdc747daa4c3fdd47bc0fc40","cc6bb98cdfb740a1b03dfabce560b6d2","080ff09695c44cbda3eba841774d8bd9","0e107ed5bb04438e902afb87a8e7c0ee","4cfa46faf9c24c0a863fa4fd20a6cfa8","b79aede50beb47ea9e755b923af8391d","771a7ae0c0a64623babac49fc0036b43","e257149b34404bf9853b7cd7086fcf25","170b8b0eb1e34f9da36d663f0ecddf68","ea621fe5e7d2426bba6de15fc3f96612","79b513996d0d4c298d2d06343a0b267b","b1590513f652475d9ed4f66ea9484cd6","d8b58cbd2ef94d61a40f167039bb9d8d","cab558c6090941ec90b42d91e0639023","2036c586c9274f7786cd28c45f47386e","8e57e977cec142f9afa32dd00bbeb776","e9983af546284b158ba02e43718a95fe","ce59fd46d9f743cda243e4ae1371de12","fa315838b55f4c82a5c2a3970ba0ef0d","35692abf6afe45cb985fc7bff95c852e","ff4b2b3a158f4b249b84a87c38449d7c","b34755bdddb14670bbe9ee7fa06c13ec","fade11ea0d774bb6ae5a7385adfdb454"]},"outputId":"cd531fd5-bc6d-43be-b94f-5487d35b47f3","id":"7LCYYO2hLvIR"},"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2024.9.post4: Fast Llama patching. Transformers = 4.44.2.\n","   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.4.1+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a8e18b5a9a54997b850e68041e66eb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/198 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9a5e05cd4914e959584e8191ed53ac2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bf321d40bad4b2f8417d923f6f250dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc6bb98cdfb740a1b03dfabce560b6d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8b58cbd2ef94d61a40f167039bb9d8d"}},"metadata":{}}],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 4096 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"]},{"cell_type":"markdown","source":["### Add Lora Adapters\n","We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"],"metadata":{"id":"BQBRCLw_M0V8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dgM7dl1XLvIR"},"outputs":[],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 64, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"]},{"cell_type":"markdown","source":["### Data Prep"],"metadata":{"id":"FNfc6OLOuuyZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GetrTh37qgDp","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["cd972867015c4d02bb93ce2909eafea3","a4e5f7c513974d32b3760c542ab2881a","784fb53ff0df4881abb7b35122fb98eb","f20dd004efb84ecbb56feaf9da3a3be4","ab98ec647acc4532adf057fd604f3b9a","35f5228fb00d45bfbbd6adc4df97bd60","14ecafbe79c543838adea31525deb1be","914f7a02f72642608a875435f5b9bbce","6d629352478c41f589380dffa8e8ec6e","bdcdc5a2ef794cd3aa719d7ada88a34f","98afeef6ad5c4860addf146140ffd221","48b865cdf1484f0089b18c5c5f6e58c1","4c9e4f9362664fb493111efe2b484401","9cdc1ed4a7db47898661c32f63154ba2","138a90b580a0466e9c0659b80cb326dc","3ffbda58942b46848a9a080f802cd53f","1ef7058c99ed4a1181e91fbffeb95d78","e4326acbdb094ffb962bec215d41c91f","d3c7ed86daa94926a9d6c5eb97d0017e","55f7b3ec518b422396c5b4628e83dd96","b5a78ff48c284204843394ccc118b44a","ee910e3521d045bc96c2664f6980a7cf","1b8926ccd7fa4cef9183daa3028447a0","937be0476940486a830ac9311060e736","1000aeaf27e541e1bdb76837a1a64391","55c50858367d4ac5ac6e2f2f9f99eec2","cb1aba1bf44244b4bc8d239e276ad9fa","e0e559accbfe4e60a8c7a9ac1bb953a2","6ad779ffd603479080223051799beb1b","0e2f32e3211d4c4e89bc819af5a2663a","ae76c9979e8b4fc8a5aff3007b4b666d","b4fb5f716e9a4a0990c38511d45056ad","8edf2cb2825149b9b6a3e70c24bc8456","ff8b88d9088642f2b9dea7d846ebba34","fa8e1dc338814c40ac9f2c43b6f31ce0","0d73322e07544869812a467d97336017","08e8e3bffb68496d8064aaf870511762","6c68d96350e44bdd9e11e087aaaeb341","418bc7a6ff5548c8b2c7c92e040816ba","fe9c833062274b5ab6a590e4d033fb91","daad9f8d340a4334813336995067a8ea","185ec0895b8042faba3032e96727e0e2","68055a764d314518bdc2f7dc2266710b","6e94b9afb60c4e3b8db4e9234f7184bf"]},"outputId":"d34ee8c1-3a43-4ca7-a545-d02626c1daed"},"outputs":[{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/490 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd972867015c4d02bb93ce2909eafea3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["dpo_fixed.jsonl:   0%|          | 0.00/34.1M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48b865cdf1484f0089b18c5c5f6e58c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/16000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b8926ccd7fa4cef9183daa3028447a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff8b88d9088642f2b9dea7d846ebba34"}},"metadata":{}}],"source":["# The data must be formatted with appropriate prompt template first.\n","# See details here: https://github.com/huggingface/trl/blob/main/examples/scripts/orpo.py\n","\n","alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n","\n","def format_prompt(sample):\n","    instruction = sample[\"instruction\"]\n","    input       = sample[\"input\"]\n","    accepted    = sample[\"accepted\"]\n","    rejected    = sample[\"rejected\"]\n","\n","    # ORPOTrainer expects prompt/chosen/rejected keys\n","    # See: https://huggingface.co/docs/trl/main/en/orpo_trainer\n","    sample[\"prompt\"]   = alpaca_prompt.format(instruction, input, \"\")\n","    sample[\"chosen\"]   = accepted + EOS_TOKEN\n","    sample[\"rejected\"] = rejected + EOS_TOKEN\n","    return sample\n","pass\n","\n","from datasets import load_dataset\n","dataset = load_dataset(\"reciperesearch/dolphin-sft-v0.1-preference\")[\"train\"]\n","dataset = dataset.map(format_prompt,)"]},{"cell_type":"markdown","source":["### Print Random Item from Dataset"],"metadata":{"id":"7PH-7Cudu8Ja"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"89e05126-700a-4913-b942-c83940d7c8d9","id":"EQZk77yULvIS"},"outputs":[{"output_type":"stream","name":"stdout","text":["INSTRUCTION: ==================================================\n","('Below is an instruction that describes a task, paired with an input that '\n"," 'provides further context. Write a response that appropriately completes the '\n"," 'request.\\n'\n"," '\\n'\n"," '### Instruction:\\n'\n"," 'You are an AI assistant that helps people find information.\\n'\n"," '\\n'\n"," '### Input:\\n'\n"," 'Given the rationale, provide a reasonable question and answer. Step-by-step '\n"," 'reasoning process: Xkcd comics are very popular amongst internet users.\\n'\n"," ' The question and answer:\\n'\n"," '\\n'\n"," '### Response:\\n')\n","ACCEPTED: ==================================================\n","('Question: What makes Xkcd comics popular among internet users?\\n'\n"," '\\n'\n"," 'Answer: Xkcd comics are popular among internet users because of their clever '\n"," 'humor, relatable themes, and minimalist art style. They often cover topics '\n"," 'like science, technology, and life experiences, making them appealing to a '\n"," 'broad audience.<|end_of_text|>')\n","REJECTED: ==================================================\n","('Question: What is the reason behind the popularity of Xkcd comics among '\n"," 'internet users?\\n'\n"," '\\n'\n"," 'Answer: Xkcd comics are popular among internet users because they offer a '\n"," 'unique blend of humor, relatable content, and thought-provoking topics that '\n"," 'resonate with a wide range of people. The comics often address everyday '\n"," 'experiences, technology, and social issues, making them accessible and '\n"," 'enjoyable for many individuals. Additionally, the simple and minimalistic '\n"," 'art style of Xkcd comics allows for easy comprehension and sharing, '\n"," 'contributing to their widespread appeal.<|end_of_text|>')\n"]}],"source":["import pprint\n","row = dataset[1]\n","print('INSTRUCTION: ' + '=' * 50)\n","pprint.pprint(row[\"prompt\"])\n","print('ACCEPTED: ' + '=' * 50)\n","pprint.pprint(row[\"chosen\"])\n","print('REJECTED: ' + '=' * 50)\n","pprint.pprint(row[\"rejected\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oqyleKojqgDq"},"outputs":[],"source":["# Enable reward modelling stats\n","from unsloth import PatchDPOTrainer\n","PatchDPOTrainer()"]},{"cell_type":"markdown","source":["### Train Model\n","Using Huggingface TRL's `ORPOTrainer`, we do 60 steps to speed things up. However, we can set num_train_epochs = 1 for a full run, and turn off max_steps=None. TRL's `DPOTrainer` is also supported!"],"metadata":{"id":"J1ZlnJpkxIuV"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["b477612f89bb404081b8da6f51e31056","26b59a49accb4104bcfeeccf3a72c486","f9f9d3c2379f4cb785f0267b8171111e","ce96762ad9e4417a8cd2c4f0e6cc9e17","29a08a48ab7d4dd386f7dc4533048d62","f61f1da0b529412ca75c13fa29f9a5db","9e431d2f31254e08b07e44241113846e","457a6abd62324434980b7e220e1b20fd","cbbfe91a2b5643f6b569cdf71343d2f7","e0282f394b0f486ca7f6ecda13972e38","7fd84ba825794a4caeb494c80331e2f8"]},"outputId":"36cfc98c-49c3-413e-9c30-dec06c1f233e","id":"Lrm9iEGRLvIS"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b477612f89bb404081b8da6f51e31056"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["max_steps is given, it will override any value given in num_train_epochs\n"]}],"source":["from trl import ORPOConfig, ORPOTrainer\n","from unsloth import is_bfloat16_supported\n","\n","orpo_trainer = ORPOTrainer(\n","    model = model,\n","    train_dataset = dataset,\n","    tokenizer = tokenizer,\n","    args = ORPOConfig(\n","        max_length = max_seq_length,\n","        max_prompt_length = max_seq_length//2,\n","        max_completion_length = max_seq_length//2,\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        beta = 0.1,\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        lr_scheduler_type = \"linear\",\n","        max_steps = 30, # Change to num_train_epochs = 1 for full training runs\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        output_dir = \"outputs\",\n","    ),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"da7cf955-ed99-4b1d-f533-8530267c1f22","id":"OFZrQ9ouLvIS"},"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 16,000 | Num Epochs = 1\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 30\n"," \"-____-\"     Number of trainable parameters = 167,772,160\n","Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [30/30 01:30, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>rewards / chosen</th>\n","      <th>rewards / rejected</th>\n","      <th>rewards / accuracies</th>\n","      <th>rewards / margins</th>\n","      <th>logps / rejected</th>\n","      <th>logps / chosen</th>\n","      <th>logits / rejected</th>\n","      <th>logits / chosen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.458000</td>\n","      <td>-0.181352</td>\n","      <td>-0.095583</td>\n","      <td>0.000000</td>\n","      <td>-0.085769</td>\n","      <td>-0.955831</td>\n","      <td>-1.813524</td>\n","      <td>-0.575378</td>\n","      <td>-0.561036</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.293000</td>\n","      <td>-0.157157</td>\n","      <td>-0.090668</td>\n","      <td>0.125000</td>\n","      <td>-0.066489</td>\n","      <td>-0.906682</td>\n","      <td>-1.571572</td>\n","      <td>-0.945717</td>\n","      <td>-0.792619</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>2.474200</td>\n","      <td>-0.120382</td>\n","      <td>-0.096684</td>\n","      <td>0.125000</td>\n","      <td>-0.023698</td>\n","      <td>-0.966840</td>\n","      <td>-1.203818</td>\n","      <td>-0.751063</td>\n","      <td>-0.750350</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>2.656400</td>\n","      <td>-0.163904</td>\n","      <td>-0.129227</td>\n","      <td>0.125000</td>\n","      <td>-0.034678</td>\n","      <td>-1.292265</td>\n","      <td>-1.639043</td>\n","      <td>-0.885241</td>\n","      <td>-0.944660</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>2.127700</td>\n","      <td>-0.117335</td>\n","      <td>-0.087243</td>\n","      <td>0.250000</td>\n","      <td>-0.030092</td>\n","      <td>-0.872427</td>\n","      <td>-1.173352</td>\n","      <td>-0.632229</td>\n","      <td>-0.599096</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>2.238700</td>\n","      <td>-0.128038</td>\n","      <td>-0.117357</td>\n","      <td>0.375000</td>\n","      <td>-0.010681</td>\n","      <td>-1.173566</td>\n","      <td>-1.280375</td>\n","      <td>-0.610937</td>\n","      <td>-0.682004</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>2.247400</td>\n","      <td>-0.097155</td>\n","      <td>-0.095071</td>\n","      <td>0.500000</td>\n","      <td>-0.002084</td>\n","      <td>-0.950708</td>\n","      <td>-0.971551</td>\n","      <td>-0.820427</td>\n","      <td>-0.886267</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>2.174700</td>\n","      <td>-0.105512</td>\n","      <td>-0.070017</td>\n","      <td>0.000000</td>\n","      <td>-0.035495</td>\n","      <td>-0.700168</td>\n","      <td>-1.055119</td>\n","      <td>-0.951585</td>\n","      <td>-0.925862</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>2.120300</td>\n","      <td>-0.115601</td>\n","      <td>-0.072845</td>\n","      <td>0.250000</td>\n","      <td>-0.042756</td>\n","      <td>-0.728450</td>\n","      <td>-1.156015</td>\n","      <td>-1.110380</td>\n","      <td>-1.154624</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>1.978800</td>\n","      <td>-0.116960</td>\n","      <td>-0.088226</td>\n","      <td>0.000000</td>\n","      <td>-0.028734</td>\n","      <td>-0.882262</td>\n","      <td>-1.169603</td>\n","      <td>-0.619079</td>\n","      <td>-0.714145</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>2.137800</td>\n","      <td>-0.127768</td>\n","      <td>-0.067682</td>\n","      <td>0.000000</td>\n","      <td>-0.060086</td>\n","      <td>-0.676820</td>\n","      <td>-1.277677</td>\n","      <td>-0.749145</td>\n","      <td>-0.828331</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>2.081100</td>\n","      <td>-0.138278</td>\n","      <td>-0.093702</td>\n","      <td>0.000000</td>\n","      <td>-0.044576</td>\n","      <td>-0.937020</td>\n","      <td>-1.382784</td>\n","      <td>-0.819674</td>\n","      <td>-0.945661</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>2.183200</td>\n","      <td>-0.131602</td>\n","      <td>-0.074887</td>\n","      <td>0.125000</td>\n","      <td>-0.056715</td>\n","      <td>-0.748873</td>\n","      <td>-1.316018</td>\n","      <td>-0.560600</td>\n","      <td>-0.493411</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>1.984400</td>\n","      <td>-0.106022</td>\n","      <td>-0.068242</td>\n","      <td>0.000000</td>\n","      <td>-0.037780</td>\n","      <td>-0.682415</td>\n","      <td>-1.060217</td>\n","      <td>-0.823509</td>\n","      <td>-0.890884</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>1.979500</td>\n","      <td>-0.129331</td>\n","      <td>-0.106232</td>\n","      <td>0.000000</td>\n","      <td>-0.023098</td>\n","      <td>-1.062325</td>\n","      <td>-1.293305</td>\n","      <td>-0.567848</td>\n","      <td>-0.610321</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>2.029000</td>\n","      <td>-0.134811</td>\n","      <td>-0.083577</td>\n","      <td>0.125000</td>\n","      <td>-0.051234</td>\n","      <td>-0.835770</td>\n","      <td>-1.348109</td>\n","      <td>-0.684903</td>\n","      <td>-0.743790</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>1.908900</td>\n","      <td>-0.098572</td>\n","      <td>-0.066571</td>\n","      <td>0.000000</td>\n","      <td>-0.032001</td>\n","      <td>-0.665714</td>\n","      <td>-0.985722</td>\n","      <td>-0.822952</td>\n","      <td>-0.742757</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>1.999300</td>\n","      <td>-0.128997</td>\n","      <td>-0.092018</td>\n","      <td>0.000000</td>\n","      <td>-0.036978</td>\n","      <td>-0.920185</td>\n","      <td>-1.289968</td>\n","      <td>-0.665739</td>\n","      <td>-0.843431</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>1.988500</td>\n","      <td>-0.106953</td>\n","      <td>-0.076765</td>\n","      <td>0.250000</td>\n","      <td>-0.030189</td>\n","      <td>-0.767645</td>\n","      <td>-1.069531</td>\n","      <td>-0.778042</td>\n","      <td>-0.770011</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>1.693300</td>\n","      <td>-0.113524</td>\n","      <td>-0.085248</td>\n","      <td>0.250000</td>\n","      <td>-0.028276</td>\n","      <td>-0.852479</td>\n","      <td>-1.135239</td>\n","      <td>-0.476717</td>\n","      <td>-0.667999</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>1.740400</td>\n","      <td>-0.089653</td>\n","      <td>-0.055689</td>\n","      <td>0.000000</td>\n","      <td>-0.033964</td>\n","      <td>-0.556887</td>\n","      <td>-0.896527</td>\n","      <td>-0.660586</td>\n","      <td>-0.791756</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>1.863100</td>\n","      <td>-0.139346</td>\n","      <td>-0.131780</td>\n","      <td>0.125000</td>\n","      <td>-0.007566</td>\n","      <td>-1.317801</td>\n","      <td>-1.393460</td>\n","      <td>-0.688972</td>\n","      <td>-0.864323</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>1.748000</td>\n","      <td>-0.110574</td>\n","      <td>-0.089563</td>\n","      <td>0.125000</td>\n","      <td>-0.021011</td>\n","      <td>-0.895634</td>\n","      <td>-1.105743</td>\n","      <td>-0.547437</td>\n","      <td>-0.490506</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>1.788400</td>\n","      <td>-0.114282</td>\n","      <td>-0.080247</td>\n","      <td>0.125000</td>\n","      <td>-0.034035</td>\n","      <td>-0.802472</td>\n","      <td>-1.142821</td>\n","      <td>-0.630544</td>\n","      <td>-0.702590</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>1.859600</td>\n","      <td>-0.146265</td>\n","      <td>-0.081249</td>\n","      <td>0.125000</td>\n","      <td>-0.065016</td>\n","      <td>-0.812492</td>\n","      <td>-1.462653</td>\n","      <td>-0.531099</td>\n","      <td>-0.521670</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>1.739600</td>\n","      <td>-0.127918</td>\n","      <td>-0.094037</td>\n","      <td>0.125000</td>\n","      <td>-0.033880</td>\n","      <td>-0.940374</td>\n","      <td>-1.279178</td>\n","      <td>-0.617654</td>\n","      <td>-0.632451</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>1.837200</td>\n","      <td>-0.143394</td>\n","      <td>-0.091317</td>\n","      <td>0.250000</td>\n","      <td>-0.052078</td>\n","      <td>-0.913166</td>\n","      <td>-1.433944</td>\n","      <td>-0.566247</td>\n","      <td>-0.642714</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>1.609200</td>\n","      <td>-0.103765</td>\n","      <td>-0.067611</td>\n","      <td>0.000000</td>\n","      <td>-0.036154</td>\n","      <td>-0.676110</td>\n","      <td>-1.037652</td>\n","      <td>-0.327126</td>\n","      <td>-0.609477</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>1.866200</td>\n","      <td>-0.117405</td>\n","      <td>-0.079740</td>\n","      <td>0.000000</td>\n","      <td>-0.037665</td>\n","      <td>-0.797396</td>\n","      <td>-1.174047</td>\n","      <td>-0.806202</td>\n","      <td>-0.954418</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>1.823100</td>\n","      <td>-0.145332</td>\n","      <td>-0.063391</td>\n","      <td>0.000000</td>\n","      <td>-0.081941</td>\n","      <td>-0.633905</td>\n","      <td>-1.453319</td>\n","      <td>-0.511081</td>\n","      <td>-0.728054</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=30, training_loss=2.0209736227989197, metrics={'train_runtime': 94.3364, 'train_samples_per_second': 2.544, 'train_steps_per_second': 0.318, 'total_flos': 0.0, 'train_loss': 2.0209736227989197, 'epoch': 0.015})"]},"metadata":{},"execution_count":18}],"source":["orpo_trainer.train()"]},{"cell_type":"markdown","source":["<a name=\"Inference\"></a>\n","### Inference\n","Let's run the model! You can change the instruction and input - leave the output blank!"],"metadata":{"id":"FgEvCW76xblp"}},{"cell_type":"code","source":["def print_formatted_prompt(prompts):\n","    \"\"\"\n","    Format and print the given prompt in a readable format.\n","\n","    :param prompt: A single string prompt that includes instruction, input, and output.\n","    \"\"\"\n","    # Remove special tags\n","    prompt = prompts[0]\n","    prompt_cleaned = prompt.replace(\"<|begin_of_text|>\", \"\").replace(\"<|end_of_text|>\", \"\")\n","\n","    # Split into sections: Instruction, Input, Output\n","    sections = prompt_cleaned.split(\"### \")\n","\n","    # Store formatted output components\n","    formatted_output = {}\n","\n","    # Parse the sections\n","    for section in sections:\n","        if section.startswith(\"Instruction:\"):\n","            formatted_output[\"Instruction\"] = section.replace(\"Instruction:\\n\", \"\").strip()\n","        elif section.startswith(\"Input:\"):\n","            formatted_output[\"Input\"] = section.replace(\"Input:\\n\", \"\").strip()\n","        elif section.startswith(\"Output:\"):\n","            formatted_output[\"Output\"] = section.replace(\"Output:\\n\", \"\").strip()\n","\n","    # Print each section in a clean format\n","    print(\"-----Formatted Prompt Output-----\")\n","    print(\"Instruction:\\n\", formatted_output.get(\"Instruction\", \"N/A\"))\n","    print(\"\\nInput:\\n\", formatted_output.get(\"Input\", \"N/A\"))\n","    print(\"\\nOutput:\\n\", formatted_output.get(\"Output\", \"N/A\"))\n","    print(\"---------------------------------\\n\")"],"metadata":{"id":"DMeoF93aS64B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"Continue the fibonnaci sequence.\", # instruction\n","        \"1, 1, 2, 3, 5, 8\", # input\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","tokenizer.batch_decode(outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0DJPbbtGxcFJ","outputId":"86620790-ae9b-4952-ea98-33f523e699c1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nContinue the fibonnaci sequence.\\n\\n### Input:\\n1, 1, 2, 3, 5, 8\\n\\n### Response:\\n13\\n\\n### Explanation:\\nThe Fibonacci sequence is a series of numbers where each number is the sum of the previous two numbers. The first two numbers are always 1, and the third number is 1 again. So the next number in the sequence after 8 would be 5 + 8 = 13.']"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["#### Define Basic Template for Alpaca Prompt"],"metadata":{"id":"4x_XTa_LROCm"}},{"cell_type":"code","source":["# Define a basic template for alpaca_prompt\n","alpaca_prompt = \"### Instruction:\\n{}\\n### Input:\\n{}\\n### Output:\\n{}\"\n","FastLanguageModel.for_inference(model)  # Enable native 2x faster inference"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sfivXtK_RN7R","outputId":"023e4b95-0ca5-4dbe-db1a-256e3a9dd700"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): LlamaForCausalLM(\n","      (model): LlamaModel(\n","        (embed_tokens): Embedding(128256, 4096)\n","        (layers): ModuleList(\n","          (0-31): 32 x LlamaDecoderLayer(\n","            (self_attn): LlamaAttention(\n","              (q_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=64, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=64, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=64, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=64, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=64, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=64, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=64, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=64, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): LlamaMLP(\n","              (gate_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=64, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=64, out_features=14336, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=64, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=64, out_features=14336, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=14336, out_features=64, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=64, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","          )\n","        )\n","        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n","        (rotary_emb): LlamaRotaryEmbedding()\n","      )\n","      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["#### Sentiment Analysis"],"metadata":{"id":"JsuOIAcERNxl"}},{"cell_type":"code","source":["inputs_sentiment = tokenizer(\n","    [\n","        alpaca_prompt.format(\n","            \"Analyze the sentiment of the given text. Return either Neutral, Positive or Negative.\",  # Instruction\n","            \"The food was disgusting!\",  # Input text for sentiment analysis\n","            \"\",  # Output - leave this blank for generation!\n","        )\n","    ], return_tensors=\"pt\"\n",").to(\"cuda\")\n","outputs_sentiment = model.generate(**inputs_sentiment, max_new_tokens=32, use_cache=True)"],"metadata":{"id":"S3YoP3qNRNpU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Sentiment Analysis Result:\")\n","print_formatted_prompt(tokenizer.batch_decode(outputs_sentiment))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ZfZBr99SO5m","outputId":"f7272583-dc72-4052-a129-1fe2155f81a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentiment Analysis Result:\n","-----Formatted Prompt Output-----\n","Instruction:\n"," Analyze the sentiment of the given text. Return either Positive, Negative, or Neutral.\n","\n","Input:\n"," I really enjoyed the movie. It was fantastic!\n","\n","Output:\n"," Positive\n","---------------------------------\n","\n"]}]},{"cell_type":"markdown","source":["#### Named Entity Recognition (NER)"],"metadata":{"id":"0ONZUVRYRNjU"}},{"cell_type":"code","source":["inputs_ner = tokenizer(\n","    [\n","        alpaca_prompt.format(\n","            \"Identify named entities (i.e. Person, Organizations, and Locations) in the given text. The output should be in list format (i.e. [People: Charles, Organizations: NATO, Locations: Cuba])\",  # Instruction\n","            \"Apple is looking at buying a startup in London for $1 billion.\",  # Input text for NER\n","            \"\",  # Output - leave this blank for generation!\n","        )\n","    ], return_tensors=\"pt\"\n",").to(\"cuda\")\n","outputs_ner = model.generate(**inputs_ner, max_new_tokens=64, use_cache=True)"],"metadata":{"id":"pZMEGJvWRNdj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Named Entity Recognition Result:\")\n","print_formatted_prompt(tokenizer.batch_decode(outputs_ner))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nZuGnEflSV5T","outputId":"eb5f7408-293c-4784-96af-5acc17027826"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Named Entity Recognition Result:\n","-----Formatted Prompt Output-----\n","Instruction:\n"," Identify named entities (i.e. Person, Organizations, and Locations) in the given text. The output should be in list format (i.e. [People: Charles, Organizations: NATO, Locations: Cuba])\n","\n","Input:\n"," Barack Obama was born in Hawaii and was the president of the United States.\n","\n","Output:\n"," [People: Barack Obama, Locations: Hawaii, Organizations: United States]\n","---------------------------------\n","\n"]}]},{"cell_type":"markdown","source":["#### Text Classification"],"metadata":{"id":"c9zhhWR8RNXy"}},{"cell_type":"code","source":["inputs_classification = tokenizer(\n","    [\n","        alpaca_prompt.format(\n","            \"Classify the given text into one of the following categories: Politics, Sports, Technology, Health, or Entertainment. Your output should only be one of these categories, whichever most closely aligns with the input.\",  # Instruction\n","            \"Apple is looking at buying a startup in London for $1 billion.\",  # Input text for classification\n","            \"\",  # Output - leave this blank for generation!\n","        )\n","    ], return_tensors=\"pt\"\n",").to(\"cuda\")\n","outputs_classification = model.generate(**inputs_classification, max_new_tokens=32, use_cache=True)"],"metadata":{"id":"ql2vDFnMRNRo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Text Classification Result:\")\n","print_formatted_prompt(tokenizer.batch_decode(outputs_classification))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lXIIWZQQSZP2","outputId":"67cb49a6-9f7a-458b-e2c0-1577ff900ddb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Text Classification Result:\n","-----Formatted Prompt Output-----\n","Instruction:\n"," Classify the given text into one of the following categories: Politics, Sports, Technology, Health, or Entertainment. Your output should only\n","\n","Input:\n"," The new AI research papers show advancements in natural language understanding.\n","\n","Output:\n"," Technology\n","---------------------------------\n","\n"]}]},{"cell_type":"markdown","source":["#### Text Summarization"],"metadata":{"id":"_WgIE2eCRND9"}},{"cell_type":"code","source":["inputs_summarization = tokenizer(\n","    [\n","        alpaca_prompt.format(\n","            \"Summarize the following article into one sentence. It is important that only one sentence is used.\",  # Instruction\n","            \"Named Entity Recognition (NER) is a common task in Machine Learning (ML) and Natural Language Processing (NLP) that involves identifying and classifying entities in text into predefined categories such as names, organizations, locations, dates, etc.\",  # Input text for summarization\n","            \"\",  # Output - leave this blank for generation!\n","        )\n","    ], return_tensors=\"pt\"\n",").to(\"cuda\")\n","outputs_summarization = model.generate(**inputs_summarization, max_new_tokens=64, use_cache=True)"],"metadata":{"id":"6KBp1oVXReLE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Text Summarization Result:\")\n","print_formatted_prompt(tokenizer.batch_decode(outputs_summarization))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BkjnJr01Sdbi","outputId":"f198d8f7-4594-49cd-dd4e-fab96e5db0c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Text Summarization Result:\n","-----Formatted Prompt Output-----\n","Instruction:\n"," Summarize the following article into one sentence. It is important that only one sentence is used.\n","\n","Input:\n"," Machine learning has seen rapid advancements over the past decade, with applications ranging from natural language processing to computer vision. Researchers have developed new algorithms and models, such as transformers, which have drastically improved performance across a variety of tasks.\n","\n","Output:\n"," The rapid advancements in machine learning over the past decade have led to the development of new algorithms and models, such as transformers, which have improved performance across a variety of tasks.\n","---------------------------------\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"lSwMmZbFh4yw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Topic Modeling"],"metadata":{"id":"yp0xv-sqRxDo"}},{"cell_type":"code","source":["inputs_topic_modeling = tokenizer(\n","    [\n","        alpaca_prompt.format(\n","            \"Identify the main topic of the given text.\",  # Instruction\n","            \"Quantum computing uses quantum-mechanical phenomena such as superposition and entanglement to perform computation. Quantum computers are different from classical computers in many ways.\",  # Input text for topic modeling\n","            \"\",  # Output - leave this blank for generation!\n","        )\n","    ], return_tensors=\"pt\"\n",").to(\"cuda\")\n","outputs_topic_modeling = model.generate(**inputs_topic_modeling, max_new_tokens=32, use_cache=True)\n"],"metadata":{"id":"hyIGCWVWh-2a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Topic Modeling Result:\")\n","print_formatted_prompt(tokenizer.batch_decode(outputs_topic_modeling))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7d91d4bd-fdff-4743-be96-726bb930919a","id":"0QMcIgq_h-2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Topic Modeling Result:\n","-----Formatted Prompt Output-----\n","Instruction:\n"," Identify the main topic of the given text.\n","\n","Input:\n"," Quantum computing uses quantum-mechanical phenomena such as super\n","\n","Output:\n"," Quantum computing\n","---------------------------------\n","\n"]}]},{"cell_type":"markdown","source":["#### Text Generation"],"metadata":{"id":"2X8bpOlvRyY0"}},{"cell_type":"code","source":["inputs_text_generation = tokenizer(\n","    [\n","        alpaca_prompt.format(\n","            \"Generate a short creative story based on the given prompt.\",  # Instruction\n","            \"Once upon a time there lived a tortoise and a boy named Alex Cross...\",  # Input text for text generation\n","            \"\",  # Output - leave this blank for generation!\n","        )\n","    ], return_tensors=\"pt\"\n",").to(\"cuda\")\n","outputs_text_generation = model.generate(**inputs_text_generation, max_new_tokens=128, use_cache=True)"],"metadata":{"id":"fb3pxYo1RiuF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Text Generation Result:\")\n","print_formatted_prompt(tokenizer.batch_decode(outputs_text_generation))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FKGzXQMEVF1D","outputId":"d3709ea7-ce56-4c56-b0f3-7eb76570f6e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Text Generation Result:\n","-----Formatted Prompt Output-----\n","Instruction:\n"," Generate a short creative story based on the given prompt.\n","\n","Input:\n"," Once upon a time in a small village, there was a mysterious forest that no one dared to enter. One day, a young child named Alex...\n","\n","Output:\n"," Once upon a time in a small village, there was a mysterious forest that no one dared to enter. One day, a young child named Alex decided to venture into the forest to explore its secrets. As he entered the forest, he noticed that the trees were all twisted and gnarled, and the leaves were a deep shade of green. He also noticed a strange smell in the air, like something was rotting. Alex walked deeper into the forest, and soon he came across a large clearing. In the middle of the clearing was a giant tree with a large hole in the center. Alex walked up to the tree and looked inside\n","---------------------------------\n","\n"]}]}]}